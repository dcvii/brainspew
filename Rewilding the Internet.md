# We Need To Rewild The Internet

The internet has become an extractive and fragile monoculture. But we can revitalize it using lessons learned by ecologists.

April 2024
25 min. read
[View original](https://www.noemamag.com/we-need-to-rewild-the-internet/)

---

_==“The word for world is forest” — Ursula K. Le Guin==_

In the late 18th century, officials in Prussia and Saxony began to rearrange their complex, diverse forests into straight rows of single-species trees. Forests had been sources of food, grazing, shelter, medicine, bedding and more for the people who lived in and around them, but to the early modern state, they were simply a source of timber.

So-called “scientific forestry” was that century’s growth hacking. It made timber yields easier to count, predict and harvest, and meant owners no longer relied on skilled local foresters to manage forests. They were replaced with lower-skilled laborers following basic algorithmic instructions to keep the monocrop tidy, the understory bare.

Information and decision-making power now flowed straight to the top. Decades later when the first crop was felled, vast fortunes were made, tree by standardized tree. The clear-felled forests were replanted, with hopes of extending the boom. Readers of the American political anthropologist of [anarchy](https://theanarchistlibrary.org/library/james-c-scott-two-cheers-for-anarchism) and order, James C. Scott, know [what happened](https://files.libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf) next.

It was a disaster so bad that a new word, _Waldsterben_, or “forest death,” was minted to describe the result. All the same species and age, the trees were flattened in storms, ravaged by insects and disease — even the survivors were spindly and weak. Forests were now so tidy and bare, they were all but dead. The first magnificent bounty had not been the beginning of endless riches, but a one-off harvesting of millennia of soil wealth built up by biodiversity and symbiosis. Complexity was the goose that laid golden eggs, and she had been slaughtered.

The story of German scientific forestry transmits a timeless truth: When we simplify complex systems, we destroy them, and the devastating consequences sometimes aren’t obvious until it’s too late.

That impulse to scour away the messiness that makes life resilient is what many conservation biologists [call](https://www.jstor.org/stable/2386849) the “pathology of command and control.” Today, the same drive to centralize, control and extract has driven the internet to the [same fate](https://www.nytimes.com/2023/12/21/opinion/internet-aging-gen-z.html) as the ravaged forests.

The internet’s 2010s, its boom years, may have been the first glorious harvest that exhausted a one-time bonanza of diversity. The complex web of human interactions that thrived on the internet’s initial technological diversity is now corralled into globe-spanning [data-extraction](https://knowledge.wharton.upenn.edu/article/data-shared-sold-whats-done/) engines making huge fortunes for a tiny few.

Our online spaces are not ecosystems, though tech firms love [that word](https://crookedtimber.org/2022/12/08/your-platform-is-not-an-ecosystem/). They’re plantations; highly concentrated and controlled environments, closer kin to the industrial farming of the cattle feedlot or battery chicken farms that madden the creatures trapped within.

We all know this. We see it each time we reach for our phones. But what most people have missed is how this concentration reaches deep into the internet’s infrastructure — the pipes and protocols, cables and networks, search engines and browsers. These structures determine how we build and use the internet, now and in the future.

They’ve concentrated into a series of near-planetary duopolies. For example, as of April 2024, Google and Apple’s internet browsers have [captured](https://gs.statcounter.com/browser-market-share/) almost 85% of the world market share, Microsoft and Apple’s two desktop operating systems over [80%](https://www.statista.com/statistics/268237/global-market-share-held-by-operating-systems-since-2009/). Google [runs](https://gs.statcounter.com/search-engine-host-market-share) 84% of global search and Microsoft 3%. Slightly more than half of all phones [come from](https://gs.statcounter.com/vendor-market-share/mobile) Apple and Samsung, while over 99% of mobile operating systems [run on](https://gs.statcounter.com/os-market-share/mobile/worldwide) Google or Apple software. Two cloud computing providers, Amazon Web Services and Microsoft’s Azure [make up](https://www.hava.io/blog/2024-cloud-market-share-analysis-decoding-industry-leaders-and-trends#:~:text=Amazon%20Web%20Services%20(AWS)%20maintains,in%20the%20Asia%2DPacific%20market.) over 50% of the global market. Apple and Google’s email clients [manage](https://www.litmus.com/email-client-market-share) nearly 90% of global email. Google and Cloudflare serve around 50% of global domain name system requests.

Two kinds of everything may be enough to fill a fictional ark and repopulate a ruined world, but can’t run an open, global “network of networks” where everyone has the same chance to innovate and compete. No wonder internet engineer Leslie Daigle [termed](https://www.thinkingcat.com/wordpress/wp-content/uploads/2020/08/2019-InvariantsUpdated.pdf) the concentration and consolidation of the internet’s technical architecture “‘climate change’ of the Internet ecosystem.”

## **Walled Gardens Have Deep Roots**

The internet made the tech giants possible. Their services have scaled globally, via its open, interoperable core. But for the past decade, they’ve also worked to enclose the varied, competing and often open-source or collectively provided services the internet is built on into their proprietary domains. Although this improves their operational efficiency, it also ensures that the flourishing conditions of their own emergence aren’t repeated by potential competitors. For tech giants, the long period of open internet evolution is over. Their internet is not an ecosystem. It’s a zoo.

Google, Amazon, Microsoft and Meta are consolidating their control deep into the underlying infrastructure through acquisitions, vertical integration, building proprietary networks, creating chokepoints and concentrating functions from different technical layers into a single silo of top-down control. They can afford to, using the vast wealth reaped in their one-off harvest of collective, global wealth.

> “That impulse to scour away the messiness that makes life resilient is what many conservation biologists call the ‘pathology of command and control.’”

Taken together, the enclosure of infrastructure and imposition of technology monoculture forecloses our futures. Internet people like to talk about “the stack,” or the layered architecture of protocols, software and hardware, operated by different service providers that collectively delivers the daily miracle of connection. It’s a complicated, dynamic system with a basic value baked into the core design: Key functions are kept separate to ensure resilience, generality and create room for innovation.

[Initially](https://cs.stanford.edu/people/eroberts/courses/soco/projects/distributed-computing/html/history.html) funded by the U.S. military and designed by academic researchers to function in wartime, the internet evolved to work anywhere, in any condition, operated by anyone who wanted to connect. But what was a dynamic, ever-evolving game of Tetris with distinct “[players” and “layers](https://datatracker.ietf.org/doc/draft-mcfadden-cnsldtn-effects/)” is today hardening into a continent-spanning system of compacted tectonic plates. Infrastructure is not just what we see on the surface; it’s the forces below, that make mountains and power tsunamis. Whoever controls infrastructure determines the future. If you doubt that, consider that in Europe we’re still using roads and living in towns and cities the Roman Empire mapped out 2,000 years ago. 

In 2019, some internet engineers in the global standards-setting body, the Internet Engineering Task Force, raised the alarm. Daigle, a respected engineer who had previously chaired its oversight committee and internet architecture board, [wrote](https://www.thinkingcat.com/wordpress/wp-content/uploads/2020/08/2019-InvariantsUpdated.pdf) in a policy brief that consolidation meant network structures were ossifying throughout the stack, making incumbents harder to dislodge and violating a core principle of the internet: that it does not create “permanent favorites.” Consolidation doesn’t just squeeze out competition. It narrows the kinds of relationships possible between operators of different services.

As Daigle put it: “The more proprietary solutions are built and deployed instead of collaborative open standards-based ones, the less the internet survives as a platform for future innovation.” Consolidation kills collaboration between service providers through the stack by rearranging an array of different relationships — competitive, collaborative — into a single predatory one. 

Since then, standards development organizations started several initiatives to name and tackle infrastructure consolidation, but these floundered. Bogged down in technical minutiae, unable to separate themselves from their employers’ interests and deeply held professional values of [simplification and control](https://archive.org/details/whatengineerskno0000vinc), most internet engineers simply couldn’t see the forest for the trees. 

Up close, internet concentration seems too intricate to untangle; from far away, it seems too difficult to deal with. But what if we thought of the internet not as a doomsday “[hyperobject](https://books.google.com/books/about/Hyperobjects.html?id=qu5zDwAAQBAJ&source=kp_book_description),” but as a damaged and struggling ecosystem facing destruction? What if we looked at it not with helpless horror at the eldritch encroachment of its current controllers, but with compassion, constructiveness and hope? 

Technologists are great at incremental fixes, but to regenerate entire habitats, we need to learn from ecologists who take a whole-systems view. Ecologists also know how to keep going when others first ignore you and then say it’s too late, how to mobilize and work collectively, and how to build pockets of diversity and resilience that will outlast them, creating possibilities for an abundant future they can imagine but never control. We don’t need to repair the internet’s infrastructure. We need to rewild it. 

## **What Is Rewilding?**

Rewilding “aims to restore healthy ecosystems by creating wild, biodiverse spaces,” [according](https://www.iucn.org/resources/issues-brief/benefits-and-risks-rewilding) to the International Union for Conservation of Nature. More ambitious and risk-tolerant than traditional conservation, it targets entire ecosystems to make space for complex food webs and the emergence of unexpected interspecies relations. It’s less interested in saving specific endangered species. Individual species are just ecosystem components, and focusing on components loses sight of the whole. Ecosystems flourish through multiple points of contact between their many elements, just like computer networks. And like in computer networks, ecosystem interactions are multifaceted and generative. 

Rewilding has much to offer people who care about the internet. As Paul Jepson and Cain Blythe wrote in [their book](https://mitpress.mit.edu/9780262046763/rewilding/) “Rewilding: The Radical New Science of Ecological Recovery,” rewilding pays attention “to the emergent properties of interactions between ‘things’ in ecosystems … a move from linear to systems thinking.”

It’s a fundamentally cheerful and workmanlike approach to what can seem insoluble. It doesn’t micromanage. It creates room for “ecological processes [that] foster complex and self-organizing ecosystems.” Rewilding puts into practice what every good manager knows: Hire the best people you can, provide what they need to thrive, then get out of the way. It’s the opposite of command and control.

> “The complex web of human interactions that thrived on the internet’s initial technological diversity is now corralled into globe-spanning data-extraction engines making huge fortunes for a tiny few.”

Rewilding the internet is more than a metaphor. It’s a framework and plan. It gives us fresh eyes for the wicked problem of extraction and control, and new means and allies to fix it. It recognizes that ending internet monopolies isn’t just an intellectual problem. It’s an emotional one. It answers questions like: How do we keep going when the monopolies have more money and power? How do we act collectively when they suborn our community spaces, funding and networks? And how do we communicate to our allies what fixing it will look and feel like?

Rewilding is a positive vision for the networks we want to live inside, and a shared story for how we get there. It grafts a new tree onto technology’s tired old stock.

## **What Ecology Knows**

Ecology knows plenty about complex systems that technologists can benefit from. First, it knows that [shifting baselines](https://esajournals.onlinelibrary.wiley.com/doi/10.1002/fee.1794) are real.

If you were born around the 1970s, you probably remember many more dead insects on the windscreen of your parents’ car than on your own. Global land-dwelling insect populations are [dropping](https://www.science.org/doi/10.1126/science.aax9931) about 9% a decade. If you’re a geek, you probably programmed your own computer to make basic games. You certainly remember a web with more to read than the [same five](https://theconversation.com/we-spent-six-years-scouring-billions-of-links-and-found-the-web-is-both-expanding-and-shrinking-159215) websites. You may have even written your own blog.

But many people born after 2000 probably think a world with few insects, little ambient noise from birdcalls, where you regularly use only a few social media and messaging apps (rather than a whole _web_) is normal. As Jepson and Blythe wrote, shifting baselines are “where each generation assumes the nature they experienced in their youth to be normal and unwittingly accepts the declines and damage of the generations before.” Damage is already baked in. It even seems natural.

Ecology knows that shifting baselines dampen collective urgency and deepen generational divides. People who care about internet monoculture and control are often told they’re nostalgists harkening back to a pioneer era. It’s fiendishly hard to regenerate an open and competitive infrastructure for younger generations who’ve been raised to assume that two or three platforms, two app stores, two operating systems, two browsers, one cloud/mega-store and a single search engine for the world comprise _the internet_. If the internet for you is the massive sky-scraping silo you happen to live inside and the only thing you can see outside is the single, other massive sky-scraping silo, then how can you imagine anything else?

Concentrated digital power produces the same symptoms that command and control produces in biological ecosystems; acute distress punctuated by sudden collapses once tipping points are reached. What scale is needed for rewilding to succeed? It’s one thing to [reintroduce](https://www.yellowstonepark.com/things-to-do/wildlife/wolf-reintroduction-changes-ecosystem/) wolves to the 3,472 square miles of Yellowstone, and quite another to cordon off about 20 square miles of a polder (land reclaimed from a body of water) known as Oostvaardersplassen near Amsterdam. Large and diverse Yellowstone is likely complex enough to adapt to change, but Oostvaardersplassen has [struggled](https://www.theguardian.com/environment/2022/jun/21/pioneering-dutch-rewilding-project-oostvaardersplassen-works-to-rebuild-controversial-reputation-aoe).

> “Our online spaces are not ecosystems, though tech firms love that word. They’re plantations; highly concentrated and controlled environments … that madden the creatures trapped within.”

In the 1980s, the Dutch government attempted to regenerate a section of the overgrown Oostvaardersplassen. An independent-minded government ecologist, Frans Vera, said reeds and scrub would dominate unless now-extinct herbivores grazed them. In place of ancient aurochs, the state forest management agency introduced the [famously bad-tempered](https://www.popsci.com/nazi-bred-cows-are-too-ferocious-farm/) German Heck cattle and in place of an extinct steppe pony, a Polish semi-feral breed.

Some 30 years on, with no natural predators, and after plans for a wildlife corridor to another reserve came to nothing, there were many more animals than the limited winter vegetation could sustain. People were [horrified](https://www.theguardian.com/environment/2018/apr/27/dutch-rewilding-experiment-backfires-as-thousands-of-animals-starve) by starving cows and ponies, and beginning in 2018, government agencies instituted animal welfare checks and culling.

Just turning the clock back was insufficient. The segment of Oostvaardersplassen was too small and too disconnected to be rewilded. Because the animals had nowhere else to go, overgrazing and collapse was inevitable, an embarrassing but necessary lesson. Rewilding is a work in progress. It’s not about trying to revert ecosystems to a mythical Eden. Instead, rewilders seek to rebuild resilience by restoring autonomous natural processes and letting them operate at scale to generate complexity. But rewilding, itself a human intervention, can take several turns to get right.  

Whatever we do, the internet isn’t returning to old-school then-common interfaces like FTP and Gopher, or organizations operating their own mail servers again instead of off-the-shelf solutions like G-Suite. But some of what we need is already here, especially on the web. Look at the resurgence of RSS feeds, email newsletters and blogs, as we discover (yet again) that relying on one app to host global conversations creates a single point of failure and control. New systems are growing, like the [Fediverse](https://www.theverge.com/24063290/fediverse-explained-activitypub-social-media-open-protocol) with its federated islands, or Bluesky with [algorithmic choice](https://bsky.social/about/blog/3-30-2023-algorithmic-choice) and [composable moderation](https://bsky.social/about/blog/4-13-2023-moderation). 

We don’t know what the future holds. Our job is to keep open as much opportunity as we can, trusting that those who come later will use it. Instead of setting purity tests for which kind of internet is most like the original, we can test changes against the values of the original design. Do new standards protect the network’s “generality,” i.e. its ability to support multiple uses, or is functionality limited to optimize efficiency for the biggest tech firms?

As early as 1985, plant ecologists Steward T.A. Pickett and Peter S. White [wrote](https://www.sciencedirect.com/book/9780125545204/the-ecology-of-natural-disturbance-and-patch-dynamics#book-info) in “The Ecology of Natural Disturbance and Patch Dynamics,” that an “essential paradox of wilderness conservation is that we seek to preserve what must change.” Some internet engineers know this. David Clark, a Massachusetts Institute of Technology professor who worked on some of the internet’s earliest protocols, [wrote](https://mitpress.mit.edu/9780262547703/designing-an-internet/) an entire book about other network architectures that might have been built if different values, like security or centralized management, had been prioritized by the internet’s creators.

But our internet took off because it was designed as a general-purpose network, built to connect anyone.

Our internet was built to be complex and unbiddable, to do things we cannot yet imagine. When we interviewed Clark, he told us that “‘complex’ implies a system in which you have emergent behavior, a system in which you can’t model the outcomes. Your intuitions may be wrong. But a system that’s too simple means lost opportunities.” Everything we collectively make that’s worthwhile is complex and thereby a little messier. The cracks are where new people and ideas get in.

Internet infrastructure is a degraded ecosystem, but it’s also a built environment, like a city. Its unpredictability makes it generative, worthwhile and deeply human. In 1961, Jane Jacobs, an American-Canadian activist and author of “The Death and Life of Great American Cities,” [argued](https://www.penguinrandomhouse.com/books/86058/the-death-and-life-of-great-american-cities-by-jane-jacobs/) that mixed-use neighborhoods were safer, happier, more prosperous, and [more livable than](https://savingplaces.org/stories/a-tale-of-two-planners-jane-jacobs-and-robert-moses) the sterile, highly [controlling](https://www.bloomberg.com/news/articles/2017-07-09/robert-moses-and-his-racist-parkway-explained) designs of urban planners like New York’s Robert Moses.

> “As a top-down, built environment, the internet has become something that is done to us, not something we collectively remake every day.”

Just like the crime-ridden, Corbusier-like towers Moses crammed people into when he demolished mixed-use neighborhoods and built highways through them, today’s top-down, concentrated internet is, for many, an unpleasant and harmful place. Its owners are hard to remove, and their interests do not align with ours.

As Jacobs wrote: “As in all Utopias, the right to have plans of any significance belonged only to the planners in charge.” As a top-down, built environment, the internet has become something that is done to us, not something we collectively remake every day. 

Ecosystems endure because species serve as checks and balances on each other. They have different modes of interaction, not just extraction, but mutualism, commensalism, competition and predation. In flourishing ecosystems, predators are subject to [limits](https://www.livingwithwolves.org/wolf-science-weekly/). They’re just one part of a complex web that passes calories around, not a one-way ticket to the end of evolution. 

Ecologists know that diversity is resilience.

On July 18, 2001, 11 carriages of a 60-car freight train [derailed](https://www.ntsb.gov/investigations/AccidentReports/Reports/RAB0408.pdf) in the Howard Street Tunnel under Mid-Town Belvedere, a neighborhood just north of downtown Baltimore. Within minutes, one carriage containing a highly flammable chemical was punctured. The escaping chemical ignited, and soon, adjacent carriages were alight in a fire that took about five days to put out. The disaster multiplied and spread. Thick, brick tunnel walls [acted like](https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=900095) an oven, and temperatures rose to nearly 2,000 degrees Fahrenheit. A more than three-foot-wide water main above the tunnels burst, flooding the tunnel with millions of gallons within hours. It only cooled a little. Three weeks later, an explosion [linked](https://mde.maryland.gov/programs/pressroom/Pages/436.aspx) to the combustible chemical [blew out](https://www.bullsheet.com/bullsheet.com/tunnelfire.html) manhole covers located as far as two miles away. 

WorldCom, then the second largest long-distance phone company in the U.S., had fiber-optic cables in the tunnel carrying high volumes of phone and internet traffic. However, according to Clark, the MIT professor, WorldCom’s resilience planning meant traffic was spread over different fiber networks in anticipation of just this kind of event.

On paper, WorldCom had network redundancy. But almost immediately, U.S. internet traffic [slowed](https://www.nytimes.com/2001/07/20/us/fire-in-baltimore-snarls-internet-traffic-too.html), and WorldCom’s East Coast and transatlantic phone lines went down. The region’s narrow physical topography had concentrated all those different fiber networks into a single chokepoint, the Howard Street Tunnel. WorldCom’s resilience was, quite literally, incinerated. It had technological redundancy, but not diversity. Sometimes we don’t notice concentration until it’s too late.

Clark tells the story of the Howard Street Tunnel fire to show that bottlenecks aren’t always obvious, especially at the operational level, and huge systems that seem secure, due to their size and resources, can unexpectedly crumble. 

In today’s internet, much traffic [passes](https://www.wsj.com/articles/google-amazon-meta-and-microsoft-weave-a-fiber-optic-web-of-power-11642222824) through tech firms’ private networks, for example, Google and Meta’s own undersea cables. Much internet traffic is served from a few dominant content distribution networks, like Cloudflare and Akamai, who run their own networks of proxy servers and data centers. Similarly, that traffic goes through an increasingly small number of domain name system (DNS) resolvers, which work like phone books for the internet, linking website names to their numeric address.

All of this improves network speed and efficiency but creates new and non-obvious bottlenecks like the Howard Street Tunnel. Centralized service providers say they’re better resourced and skilled at attacks and failures, but they are also large, [attractive targets](https://www.tandfonline.com/doi/full/10.1080/23738871.2020.1728355) for attackers and possible single points of system failure.

On Oct. 21, 2016, dozens of major U.S. websites suddenly stopped working. Domain names belonging to Airbnb, Amazon, PayPal, CNN and The New York Times simply didn’t resolve. All were clients of the commercial DNS service provider, Dyn, which had been hit by a cyberattack. Hackers infected [tens of thousands](https://coverlink.com/case-study/mirai-ddos-attack-on-dyn/#:~:text=Impacted%20internet%20platforms%20included%20PayPal,platforms%20in%20approximately%20two%20hours) of internet-enabled devices with malicious software, creating a network of hijacked devices, or a botnet, that they used to bombard Dyn with queries until it collapsed. America’s biggest internet brands were brought down by nothing more than a network of [baby monitors](https://www.washingtonpost.com/opinions/the-day-of-the-zombie-baby-monitors-when-hackers-weaponized-the-internet-of-things/2016/10/25/167fdf42-9a1b-11e6-b3c9-f662adaa0048_story.html), security webcams and other consumer devices. Although they all likely had resilience planning and redundancies, they went down because a single chokepoint — in one crucial layer of infrastructure — failed.

> “Crashes, fires and floods may simply be entropy in action, but systemically concentrated and risky infrastructures are choices made manifest — and we can make better ones.”

Widespread outages due to centralized chokepoints have become so common that investors even use them to identify opportunities. When a failure by cloud provider Fastly took high-profile websites offline in 2021, its share price [surged](https://www.ft.com/content/4c68df91-98d1-4942-87cf-f734ea2cdd73). Investors were delighted by headlines that informed them of an obscure technical service provider with an apparent lock on an essential service. To investors, this critical infrastructure failure doesn’t look like fragility but like a chance to profit.

The result of infrastructural narrowness is baked-in fragility that we only notice after a breakdown. But monoculture is also highly visible in our search and browser tools. Search, browsing and social media are how we find and share knowledge and how we communicate. They’re a critical, global epistemic and democratic infrastructure, controlled by just a few U.S. companies. Crashes, fires and floods may simply be entropy in action, but systemically concentrated and risky infrastructures are choices made manifest — and we can make better ones.  

## **The Look & Feel Of A Rewilded Internet**

A rewilded internet will have many more service choices. Some services like search and social media will be broken up, [as AT&T eventually was](https://www.eff.org/deeplinks/2021/02/what-att-breakup-teaches-us-about-big-tech-breakup). Instead of tech firms extracting and selling people’s personal data, different payment models will fund the infrastructure we need. Right now, there is little explicit provision for public goods like internet protocols and browsers, essential to making the internet work. The biggest tech firms subsidize and profoundly influence them.

Part of rewilding means taking what’s been pulled into the big tech stack back out of it, and paying for the true costs of connectivity. Some things like basic connectivity we will continue to pay for directly, and others, like browsers, we will support indirectly but transparently, as described below. The rewilded internet will have an abundance of ways to connect and relate to each other. There won’t be just one or two numbers to call if leaders of a political coup decide to shut the internet down in the middle of the night, as has happened in places like [Egypt](https://www.nytimes.com/2011/01/29/technology/internet/29cutoff.html) and [Myanmar](https://www.reuters.com/graphics/MYANMAR-POLITICS/INTERNET-RESTRICTION/rlgpdbreepo/). No one entity will permanently be on top. A rewilded internet will be a more interesting, usable, stable and enjoyable place to be.

Through extensive research, Nobel-winning economist Elinor Ostrom [found](https://www.sciencedirect.com/science/article/abs/pii/S0959378010000634) that “when individuals are well informed about the problem they face and about who else is involved, and can build settings where trust and reciprocity can emerge, grow, and be sustained over time, costly and positive actions are frequently taken without waiting for an external authority to impose rules, monitor compliance, and assess penalties.” Ostrom [found](https://www.yesmagazine.org/economy/2021/08/11/the-commons-lobster-maine-elinor-ostrom) people spontaneously organizing to manage natural resources — from water company cooperation in California to Maine lobster fishermen organizing to prevent overfishing.

Self-organization also exists as part of a key internet function: traffic coordination. Internet exchange points ([IXPs](https://www.internetsociety.org/issues/ixps/)) are an example of common-pool resource management, where internet service providers (ISPs) collectively agree to carry each other’s data for low or no cost. Network operators of all kinds — telecoms companies, large tech firms, universities, governments and broadcasters — all need to send large amounts of data through other ISPs’ networks so that it gets to its destination.

If they managed this separately through individual contracts, they’d spend much more time and money. Instead, they often form IXPs, typically as independent, not-for-profit associations. As well as managing traffic, IXPs have, in many — and especially developing — countries, formed the backbone of a flourishing technical community that further drives economic development.

Both between people and on the internet, connections are generative. From technical standards to common-pool resource management and even to more localized broadband networks known as “altnets,” internet rewilding already has a deep toolbox of collective action ready to be deployed.

## **The New Drive For Antitrust & Competition**

The list of infrastructures to be diversified is long. As well as pipes and protocols, there are operating systems, browsers, search engines, the Domain Name System, social media, advertising, cloud providers, app stores, AI companies and more. And these technologies also intertwined.

But showing what can be done in one area creates opportunities in others. First, let’s start with regulation.

You don’t always need a big new idea like rewilding to frame and motivate major structural change. Sometimes reviving an old idea will do. President Biden’s 2021 “[Executive Order](https://www.whitehouse.gov/briefing-room/presidential-actions/2021/07/09/executive-order-on-promoting-competition-in-the-american-economy/) on Promoting Competition in the American Economy” revived the original, pro-worker, trust-busting scope and urgency of the early 20th-century legal activist and Supreme Court Justice Louis D. Brandeis, along with rules and framings that date back to before the 1930s New Deal.

> “Rewilding an already built environment isn’t just sitting back and seeing what tender, living thing can force its way through the concrete. It’s razing to the ground the structures that block out light for everyone not rich enough to live on the top floor.”

U.S. antitrust law was [created](https://www.motherjones.com/politics/2023/11/how-gilded-age-lawmakers-saved-america-from-plutocracy/) to break the power of oligarchs in oil, steel and railroads who threatened America’s young democracy. It gave workers basic protections and saw equal economic opportunity as essential to freedom. This view of competition as essential was [whittled away](https://bfi.uchicago.edu/wp-content/uploads/2022/08/BFI_WP_2022-104.pdf) by Chicago School economic policies in the 1970s and Reagan-era judges’ court rulings over the decades. They [believed](https://lawreview.uchicago.edu/print-archive/chicago-school-and-forgotten-political-dimension-antitrust-law) intervention should only be permitted when monopoly power causes consumer prices to rise. The intellectual monoculture of that consumer-harm threshold has since spread globally.

It’s why governments just stood aside as 21st-century tech firms romped to oligopoly. If a regulator’s sole criterion for action is to make sure consumers don’t pay a penny more, then the free or data-subsidized services of tech platforms don’t even register. (Of course, consumers pay in other ways, as these tech giants exploit their personal information for profit.) This laissez-faire approach allowed the biggest firms to choke off competition by [acquiring](https://www.bloomberg.com/news/articles/2020-07-27/big-tech-goes-on-shopping-spree-brushing-off-antitrust-scrutiny) their competitors and vertically integrating service providers, creating the problems we have today. 

Regulators and enforcers in Washington and Brussels now say they have learned that lesson and won’t allow AI dominance to happen as internet concentration did. Federal Trade Commission Chair Lina Khan and U.S. Department of Justice antitrust [enforcer](https://www.nytimes.com/2024/03/22/technology/jonathan-kanter-apple-antitrust.html), Jonathan Kanter, are [identifying](https://www.theverge.com/2023/3/28/23660101/ai-competition-ftc-doj-lina-khan-jonathan-kanter-antitrust-summit) chokepoints in the AI “[stack](https://www.justice.gov/opa/speech/assistant-attorney-general-jonathan-kanter-delivers-remarks-22nd-international)” — concentration in control of processing chips, datasets, computing capacity, algorithm innovation, distribution platforms and user interfaces — and analyzing them to see if they affect systemic competition. This is potentially good news for people who want to prevent the current dominance of tech giants being grandfathered into our AI future. 

In his 2021 signing of the executive order on competition, President Biden [said](https://www.whitehouse.gov/briefing-room/speeches-remarks/2021/07/09/remarks-by-president-biden-at-signing-of-an-executive-order-promoting-competition-in-the-american-economy/): “Capitalism without competition isn’t capitalism; it’s exploitation.” Biden’s enforcers are changing the kinds of cases they take up and widening the applicable legal theories on harm that they bring to judges. Instead of the traditionally narrow focus on consumer prices, today’s cases argue that the economic harms perpetrated by dominant firms include those suffered by their workers, small companies and the market as a whole.

Khan and Kanter have jettisoned narrow and abstruse models of market behavior for real-world experiences of healthcare workers, farmers and writers. They _get_ that shutting off economic opportunity fuels far-right extremism. They’ve made antitrust enforcement and competition policy explicitly about coercion versus choice, power versus democracy. Kanter [told](https://bruxconference2024.clevercast.com/webcast/w-qodbzp/) a recent conference in Brussels that “excessive concentration of power is a threat … it’s not just about prices or output but it’s about freedom, liberty and opportunity.” 

Enforcers in Washington and Brussels are starting to preemptively block tech firms from using dominance in one realm to take over another. After scrutiny by the U.S. FTC and European Commission, Amazon recently [abandoned](https://www.bbc.com/news/business-68131819) its plan to acquire the home appliance manufacturer, iRobot. Regulators on both sides of the Atlantic have also moved to stop Apple from using its iPhone platform dominance to squeeze app store competition and dominate future markets through, for example, pushing the usage of CarPlay on automakers and limiting access to its tap-to-pay digital wallet in the financial services sector.

Still, so far, their [enforcement actions](https://www.nytimes.com/2024/03/04/technology/europe-apple-meta-google-microsoft.html) have focused on the consumer-facing, highly visible parts of the tech giants’ exploitative and proprietary internet. The few, narrow measures of the 2021 executive order that aim to reduce infrastructure-based monopolies, only prevent _future_ abuses like radio spectrum-hogging, not those already [locked in](https://www.vice.com/en/article/mbjpjb/a-short-history-of-wireless-spectrum-the-most-complicated-puzzle-youve-ever-seen). Sure, the best way to deal with monopolies is to stop them from happening in the first place. But unless regulators and enforcers eradicate the existing dominance of these giants now, we’ll be living in today’s infrastructure monopoly for decades, perhaps even a century.

Even activist regulators have shied away from applying the toughest remedies for concentration in long-consolidated markets, such as non-discrimination requirements, functional interoperability and structural separations, i.e. breaking companies up. And declaring that search and social media [monopolies](https://www.bnnbloomberg.ca/big-tech-s-natural-monopoly-tough-to-self-regulate-malone-says-1.1679411) are actually [public utilities](https://www.wired.com/story/no-facebook-google-not-public-utilities/) — and forcing them to act as common carriers open to all — is still too extreme for most.

But rewilding a built environment isn’t just sitting back and seeing what tender, living thing can force its way through the concrete. It’s razing to the ground the structures that block out light for everyone not rich enough to live on the top floor.

> “Ecologists have reoriented their field as a ‘crisis discipline,’ a field of study that’s not just about learning things but about saving them. We technologists need to do the same.”

When the writer and activist Cory Doctorow [wrote](https://www.noemamag.com/freeing-ourselves-from-the-clutches-of-big-tech/) about how to free ourselves from the clutches of Big Tech, he said that though breaking up big companies will likely take decades, providing strong and mandatory interoperability would open up innovative space and slow the flow of money to the largest firms — money they would otherwise use to deepen their moats.

Doctorow describes “comcom,” or competitive compatibility, as a kind of “guerrilla interoperability, achieved through reverse engineering, bots, scraping and other permissionless tactics.” Before a thicket of invasive laws sprung up to strangle it, comcom was how people figured out how to fix cars and tractors or re-write software. Comcom drives the try-every-tactic-until-one-works behavior you see in a flourishing ecosystem. 

In an ecosystem, diversity of species is another way of saying “diversity of tactics,” as each successful new tactic creates a new niche to occupy. Whether it’s an octopus camouflaging itself as a sea snake, a cuckoo smuggling her chicks into another bird’s nest, orchids producing flowers that look just like a female bee, or parasites influencing rodent hosts to take life-ending risks, each evolutionary micro-niche is created by a successful tactic. Comcom is simply tactical diversity; it’s how organisms interact in complex, dynamic systems. And humans have demonstrated the epitome of short-term thinking by enabling the oligarchs who are trying to end it.

Efforts are underway. The EU already has several years of experience with interoperability mandates and precious insight into how determined firms work to circumvent such laws. The U.S., however, is still in its early days of ensuring software interoperability, for example, for [videoconferencing](https://www.theverge.com/2024/4/8/24119268/wyden-secure-interoperable-goverment-collaboration-technology-act-encryption).

Perhaps one way to motivate and encourage regulators and enforcers everywhere is to explain that the subterranean architecture of the internet has become a shadowland where evolution has all but stopped. Regulators’ efforts to make the visible internet competitive will achieve little unless they also tackle the devastation that lies beneath. 

## **Next Steps**

Much of what we need is already here. Beyond regulators digging deep for courage, vision and bold new litigation strategies, we need vigorous, pro-competitive government policies around procurement, investments and physical infrastructure. Universities must reject research [funding from tech firms](https://www.washingtonpost.com/technology/2023/12/06/academic-research-meta-google-university-influence/) because it always comes with conditions, both spoken [and](https://edition.cnn.com/2023/12/04/tech/facebook-disinformation-whistleblower/index.html) [unspoken](https://www.newstatesman.com/science-tech/2019/06/how-big-tech-funds-debate-ai-ethics).

Instead, we need more publicly funded tech research with publicly released findings. Such research should investigate power concentration in the internet ecosystem and practical alternatives to it. We need to recognize that much of the internet’s infrastructure is a de facto utility that we must regain control of.

We must ensure regulatory and financial incentives and support for alternatives including common-pool resource management, community networks, and the myriad other collaborative mechanisms people have used to provide essential public goods like roads, defense and clean water.

All this takes money. Governments are starved of tax revenue by the once-in-history windfalls seized by today’s tech giants, so it’s clear where the money is. We need to get it back.

We know all this, but still find it so hard to collectively act. Why? 

Herded into rigid tech plantations rather than functioning, diverse ecosystems, it’s tough to imagine alternatives. Even those who can see clearly may feel helpless and alone. Rewilding unites everything we know we need to do and brings with it a whole new toolbox and vision.

Ecologists face the same systems of exploitation and are organizing urgently, at scale and across domains. They [see clearly](https://www.wbur.org/onpoint/2023/12/08/inside-the-rewilding-movement) that the issues aren’t isolated but are instances of the same pathology of command and control, extraction and domination that political anthropologist Scott first noticed in scientific forestry. The solutions are the same in ecology and technology: aggressively use the rule of law to level out unequal capital and power, then rush in to fill the gaps with better ways of doing things.

## **Keep The Internet, The Internet**

Susan Leigh Star, a sociologist and theorist of infrastructure and networks, wrote in her 1999 influential paper, “The Ethnography of Infrastructure”:

“Study a city and neglect its sewers and power supplies (as many have), and you miss essential aspects of distributional justice and planning power. Study an information system and neglect its standards, wires, and settings, and you miss equally essential aspects of aesthetics, justice, and change.”

The technical protocols and standards that underlie the internet’s infrastructure are ostensibly developed in open, collaborative standards development organizations (SDOs), but are also increasingly under the control of a few companies. What appear to be “voluntary” standards are often the business choices of the biggest firms.

The dominance of SDOs by big firms also shapes what does _not_ get standardized — for example, search, which is effectively a global monopoly. While efforts to directly [address](https://www.ietf.org/archive/id/draft-nottingham-avoiding-internet-centralization-02.html) internet consolidation have been raised [repeatedly](https://datatracker.ietf.org/doc/pdf/draft-mcfadden-cnsldtn-effects-01) within SDOs, little progress has been made. This is [damaging](https://www.gov.uk/cma-cases/investigation-into-googles-privacy-sandbox-browser-changes) SDOs’ credibility, especially outside the U.S. SDOs must radically change or they will lose their implicit global mandate to steward the future of the internet.

We need internet standards to be global, open and generative. They’re the wire models that give the internet its planetary form, the gossamer-thin but steely-strong threads holding together its interoperability against fragmentation and permanent dominance.

## ****Make Laws & Standards Work Together****

In 2018, a small group of Californians [maneuvered](https://www.nytimes.com/2018/05/13/business/california-data-privacy-ballot-measure.html) the Legislature into passing the [California Consumer Privacy Act](https://oag.ca.gov/privacy/ccpa#:~:text=The%20California%20Consumer%20Privacy%20Act,how%20to%20implement%20the%20law.). Nested in the statute was an unassuming provision, the “right to opt out of sale or sharing” your personal information via a “user-enabled global privacy control” or GPC signal that would create an automated method for doing so. The law didn’t define how GPC would work. Because a technical standard was required for browsers, businesses and providers to speak the same language, the signal’s details were delegated to a group of experts.

In July 2021, California’s attorney general [mandated](https://www.huntonprivacyblog.com/2021/07/15/california-attorney-general-updates-ccpa-faqs-indicating-mandatory-compliance-with-global-privacy-control/) that all businesses use the newly created GPC for California-based consumers visiting their websites. The group of experts is now [shepherding](https://w3cping.github.io/administrivia/2023/charter.html) the technical specification through global web standards development at the World Wide Web Consortium. For California residents, GPC automates the request to “accept” or “reject” sales of your data, such as cookie-based tracking, on its websites. However, it isn’t yet supported by major default browsers like Chrome and Safari. Broad adoption will take time, but it’s a small step in changing real-world outcomes by driving antimonopoly practices deep into the standards stack — and it’s already being [adopted](https://usercentrics.com/knowledge-hub/what-is-global-privacy-control/#:~:text=United%20States%20and%20state%2Dlevel%20laws%20and%20GPC,-Six%20new%20data&text=The%20laws%20in%20California%2C%20Connecticut,to%20respect%20Global%20Privacy%20Control.) elsewhere.

GPC is not the first legally mandated open standard, but it was deliberately designed from day one to bridge policymaking and standards-setting. The idea is gaining ground. A recent United Nations Human Rights Council [report](https://documents.un.org/doc/undoc/gen/g23/117/05/pdf/g2311705.pdf?token=2yMgO0WoPF6QcYggQX&fe=true) recommends that states delegate “regulatory functions to standard-setting organizations.”

## **Make Service-Providers — Not Users — Transparent**

Today’s internet offers minimal transparency of key internet infrastructure providers. For example, browsers are highly complex pieces of infrastructure that determine how billions of people use the web, yet they are provided for free. That’s because the most commonly used search engines enter into opaque financial deals with browsers, paying them to be set as the default. Since few people change their default search engine, browsers like Safari and Firefox [make money](https://www.forbes.com/sites/johanmoreno/2021/08/27/google-estimated-to-be-paying-15-billion-to-remain-default-search-engine-on-safari/) by defaulting the search bar to Google, locking in its dominance even as the search engine’s quality of output [declines](https://www.theatlantic.com/technology/archive/2023/09/google-search-size-usefulness-decline/675409/).

This creates a quandary. If antitrust enforcers were to impose competition, browsers would lose their main source of income. Infrastructure requires money, but the planetary nature of the internet challenges our public funding model, leaving the door open to private capture. However, if we see the current opaque system as what it is, a kind of non-state taxation, then we can craft an alternative.

Search engines are a logical place for governments to mandate the collection of a levy that supports browsers and other key internet infrastructure, which could be financed transparently under open, transnational, multistakeholder oversight.

## **Make Space To Grow**

We need to stop thinking of internet infrastructure as too hard to fix. It’s the underlying system we use for nearly everything we do. The former prime minister of Sweden, Carl Bildt, and former Canadian deputy foreign minister, Gordon Smith, [wrote](https://www.tandfonline.com/doi/full/10.1080/23738871.2016.1235908) in 2016 that the internet was becoming “the infrastructure of all infrastructure.” It’s how we organize, connect and build knowledge, even — perhaps — planetary intelligence. Right now, it’s concentrated, fragile and utterly toxic. 

Ecologists have reoriented their field as a “[crisis discipline](https://onlinelibrary.wiley.com/doi/abs/10.1111/1600-0498.12149),” a field of study that’s not just about learning things but about saving them. We technologists need to do the same. Rewilding the internet connects and grows what people are doing across regulation, standards-setting and new ways of organizing and building infrastructure, to tell a shared story of where we want to go. It’s a shared vision with many strategies. The instruments we need to shift away from extractive technological monocultures are at hand or ready to be built.

---
Maria Farrell is a writer and keynote speaker on technology and the future. She has worked on technology policy at the International Chamber of Commerce, the Internet Corporation for Assigned Names and Numbers, and the World Bank.

Robin Berjon is an expert in digital governance and has contributed to numerous web standards, including the Global Privacy Control. He works on novel web protocols like the InterPlanetary File System and sits on the World Wide Web Consortium’s Board of Directors and the UK’s Information Commissioner’s Office Technology Advisory Panel.