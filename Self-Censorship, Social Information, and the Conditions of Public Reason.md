---
title: "Self-Censorship, Social Information, and the Conditions of Public Reason"
source: "https://glennloury.substack.com/p/self-censorship-social-information?publication_id=259044&post_id=188146143&isFreemail=true&r=7br8e&triedRedirect=true"
author:
  - "[[By Glenn Loury]]"
published:
created: 2026-02-18
description:
tags:
  - "clippings"
---
Last week, I flew out to Stanford to deliver the Kenneth J. Arrow Lecture at the McCoy Family Center for Ethics in Society. Arrow was one of the great economists of the twentieth century, and I tried to write something that would both do justice to the enormity of his contributions to the discipline and deepen our understanding of the social phenomena that occupied him over the course of his long career. Below you’ll find the text as it was delivered on the day.

### Self-Censorship, Social Information, and the Conditions of Public Reason

**The Kenneth J. Arrow Lecture**

**McCoy Family Center for Ethics in Society, Stanford University**

*Delivered February 11, 2026*

**Introduction**

This lecture is about self-censorship—but not in the sense in which that term is usually deployed. I am not talking about cowardice, timidity, or failures of character. I am talking about a structural phenomenon: I analyze self-censorship as the equilibrium outcome of rational behavior in certain social and institutional settings. I take it for granted that, if we want to know what people think about some consequential issue, we shouldn’t rely on their public utterances. More candor is to be found in private than in public; more nuance in a closed seminar than in an open debate; more guileless expression in whispers than in print. Why does this gap in supply between private and public candor exist? When does it become socially disadvantageous? How can it be narrowed. This lecture endeavors to address those questions.

My central concern is that in important institutions—in the universities, the press, the scientific communities, even democratic politics—candor is in short supply. Circumspection is the order of the day, because saying what one really believes is costly. The costs of candor are reputational as well as intellectual. To speak unguardedly risks not only being refuted but being classified. Self-censorship is incentive-compatible under such conditions. Furthermore, the public discourse is systematically distorted when many respond similarly to these incentives. Apparent consensus can lose its epistemic meaning. Effective public decision-making erodes.

This is a story about incentives, information, and equilibrium behavior. It is a story that can be told using the most basic tools of information economics and decision theory. This story helps make sense of a wide range of contemporary public pathologies that are often treated as cultural anomalies or moral failures.

I will proceed in steps. I will start by explaining why self-censorship should be understood as an equilibrium phenomenon rather than a psychological anomaly. Then, I will show how multiple audiences and moralized reputational pressures produce systematic expressive distortion. Third, I will present—entirely in words—a simple model that captures the logic of these pressures and shows why truth-telling can fail to be incentive-compatible even among sincere actors. Then I’ll discuss the dynamics of this process and the conditions under which candid speech is more or less likely to emerge. I then apply these ideas to three domains of public argument where these concerns are especially acute: race, academic life, and the public discourse on Israel and Gaza. And I conclude by drawing out implications for democratic deliberation. Throughout, I do not adjudicate the conflicting moral claims at issue but try instead to illuminate how and why those claims are—or are not—candidly expressed. I am concerned less with what people believe than with what it costs them to say what they believe in public.

The argument to come would have been familiar to Ken Arrow in spirit if not in subject matter. That is why it is an honor, and awesome responsibility, to lecture under his name. Arrow’s work profoundly influenced my intellectual formation. His ideas in social choice theory and welfare economics provided a rigorous way to think about collective decision-making. By making the assumptions needed for collective rationality explicit, and by showing that those assumptions can fail, he set an inspiring standard. I learned from his information economics work that institutions matter not only by expressing values but also by shaping incentives; and that private information can be shared only imperfectly. I learned that coordination failures arise within institutions and are reproduced in equilibrium. I claim that public discourse is subject to this kind of failure, and that current discursive pathologies are best understood from this Arrow-influenced, information-theoretic point of view.

*This post is free and available to the public. The Glenn Show is almost entirely audience-supported. If you enjoy my essays, podcasts, livestreams, Q&As with John McWhorter, and all the other content you find here, **consider becoming a full subscriber**.*

[Share](https://glennloury.substack.com/p/self-censorship-social-information?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoxMjMwNTgyMiwicG9zdF9pZCI6MTg4MTQ2MTQzLCJpYXQiOjE3NzE0MzkxMDgsImV4cCI6MTc3NDAzMTEwOCwiaXNzIjoicHViLTI1OTA0NCIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.ZQQz-SdECU-aZa4A7Brl9ahb-9APGRrJQw7kS1eqx0k)

**I. Self-Censorship as a Social Equilibrium**

Begin with a simple observation. Individuals hold beliefs about the world. Some of those beliefs are relevant to collective decisions and public understanding. Speaking with candor can generate social value by improving collective knowledge. But speaking unguardedly also imposes private costs on the speaker. Those costs are not limited to being shown wrong. Intellectual refutation is something most scholars, journalists, and politicians are trained to accept. The costs that really matter here are reputational—and more specifically, moralized reputational costs. To speak in certain ways is to risk being seen not merely as mistaken, but as the wrong kind of person.

Once that possibility enters the picture, the decision problem changes. The speaker must weigh a potential epistemic benefit—often diffuse, uncertain, and enjoyed mostly by others—against a potential reputational harm that is personal, asymmetric, and durable. If the probability of persuading one’s audience is low, and if the reputational penalty for being misread is high, then silence, hedging, or affective conformity becomes the preferred strategy.

No coordination is required for this outcome to arise. Each individual responds independently to the same incentive environment. Yet when many face similar incentives, the equilibrium result can be collective silence or expressive distortion. Once such an equilibrium takes hold, silence loses its meaning. It no longer connotes agreement or ignorance. Instead, it signals caution. And public discourse ceases to reflect the distribution of beliefs in the population. It comes instead to reflect the distribution of the costs attached to expressing those beliefs.

When reputational penalties attach to certain conclusions, the people most likely to speak are either those insulated from the penalties or those who reject the moral premises of the audience altogether. Extremes become over-represented. The cautious, empirically minded middle withdraws. This is not because moderate views vanish, but because they are priced out of public expression. This process of adverse selection that Ken Arrow would have understood very well can be self-reinforcing. Once some people suppress their views, others update their beliefs about what can safely be said, and the perceived reputational risk of expressing those views increases. Silence begets silence. Ambiguity becomes the norm. Deviant speech comes to be increasingly diagnostic of the speaker’s “morally bad” type. Public deliberation becomes impoverished.

At this point, several things become true simultaneously. First, reputational penalties attach asymmetrically to certain conclusions rather than to error as such. Second, the probability that careful argument will persuade a morally committed audience falls. Third, speakers anticipate (mis)classification rather than rebuttal. And fourth, those most sensitive to reputational risk withdraw first. Under such conditions, silence and expressive distortion are not anomalies. They are the equilibrium outcome. The resulting discourse is not simply biased; it is informationally thinned out by selection.

**II. Multiple Audiences and Expressive Distortion**

The equilibrium logic I have just described becomes far more powerful once we take seriously a second feature of public life: the multiplicity of audiences.

Very little speech today is directed at a single, well-defined audience. A scholar writing an article or giving an interview speaks simultaneously to colleagues, administrators, students, journalists, donors, online critics, and future employers. Each audience hears the same words through a different lens and attaches different meanings—and has different reactions—to what is said.

This matters because reputational costs are audience-specific, but they are borne by the same individual. A statement intended as analytic may be heard as moral. A caveat may be ignored, while a single phrase is extracted and circulated far from its original context. The speaker cannot control these downstream interpretations. She can only anticipate the risk that some audience will hear her words in the most hostile possible way.

It is tempting to think that this problem is merely a byproduct of social media or mass communication. But that would be a mistake. The phenomenon predates digital platforms. What has changed is not the existence of multiple audiences, but the collapse of boundaries between them. Institutional settings once allowed speech to be addressed to distinct publics under distinct norms. When those boundaries dissolve, the most punitive interpretation comes to dominate, and the reputational risk is set by the harshest audience rather than the most reasonable one. The problem here is not merely that there is disagreement. It’s that disagreement itself has become morally legible. Speech is evaluated not primarily as an attempt to describe the world, but as evidence of who the speaker is.

Once that happens, the cost of being misunderstood can dwarf the cost of being wrong. The fear is not rebuttal, but misclassification—being sorted into a stigmatized category from which return is difficult or impossible. The rational response in such a situation is caution.

People hedge. They adopt euphemisms. They rely on ritualized phrases that signal moral alignment without committing to specific claims. They avoid topics altogether or confine candor to private settings. Over time, this behavior reshapes public discourse. Certain positions are voiced repeatedly because they have become reputationally safe; others are rarely heard because they have become discrediting to express.

This outcome does not require censorship in any formal sense. No rules need be written down. The system polices itself through anticipation. Individuals learn quickly which kinds of speech trigger backlash and adjust accordingly. The equilibrium stabilizes precisely because no single actor is responsible for it.

You can recognize this equilibrium by its signatures: moral preambles before empirical claims; appeals to “complexity” in place of causal specificity; and the careful avoidance of conclusions that might be read as signaling deviance. These are not accidents of style, not mere nods to the imperatives of decorum. They are predictable responses to incentive structures that flatten the discursive terrain.

[Share](https://glennloury.substack.com/p/self-censorship-social-information?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoxMjMwNTgyMiwicG9zdF9pZCI6MTg4MTQ2MTQzLCJpYXQiOjE3NzE0MzkxMDgsImV4cCI6MTc3NDAzMTEwOCwiaXNzIjoicHViLTI1OTA0NCIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.ZQQz-SdECU-aZa4A7Brl9ahb-9APGRrJQw7kS1eqx0k)

**III. A Simple Model**

Let me now make the underlying logic explicit with a simple model, presented entirely in words.

Imagine an individual—call her an advisor—who possesses some private information relevant to a collective decision. She may be a scholar evaluating her data, a journalist assessing a story, or a professional offering counsel. Her information is sincere and potentially valuable. She wants to improve collective decision-making but also cares about her reputation with her audience.

Now imagine the audience. The audience cares about the decision, but it also cares about moral identity. It does not observe the advisor’s intentions directly. It observes only what she says and uses that speech both to update beliefs about the real world and to infer the kind of person she is.

Imagine further that certain conclusions —fairly or not—are associated in the audience’s mind with morally stigmatized characters. Endorsing or even discussing those conclusions is taken as evidence of bias or bad faith. Other conclusions are associated with virtue or solidarity and carry little reputational risk. The advisor understands all of this. Suppose the advisor learns that the morally stigmatized conclusion happens to be correct. She now faces a choice. She can speak truthfully, revealing her information notwithstanding the fact that it affirms the stigmatized decision, thereby risking misclassification as a moral deviant. Or she can remain silent, hedge, or conform to the dominant narrative, thereby avoiding reputational harm but also withholding from her audience information that might be socially valuable.

Intuitively, two variables determine her choice. First is the probability of persuasion. If careful argument has a reasonable chance of changing minds, speaking may be worth the risk. Second is the magnitude of the reputational cost. If being misclassified carries severe and durable penalties, even a small chance of misinterpretation looms large.

So, when polarization is high and persuasion unlikely, the expected benefit of speaking candidly will collapse. When reputational penalties are moralized, durable and asymmetric, their expected cost rises. Hence, under such conditions, candor may become incentive incompatible and silence or a reflexive conformity can dominate.

Once many advisors face this same tradeoff, the equilibrium becomes self-reinforcing. Audiences hear fewer dissenting views and infer consensus. Advisors, observing apparent consensus, infer that dissent will be ignored and/or punished. Political correctness, understood this way, is not an ideological phenomenon. It emerges as an equilibrium in an information game—where speech is both informative and identity-signaling, and where the costs of misclassification overwhelm the informational value of candor. This is a revelation problem in which incentive compatibility fails. Truthful speech is socially valuable but privately costly, not because information is proprietary but because it has come to convey social meaning. The advisor’s concern is not error but stigma. If institutions fail to align private incentives with the social value of information, the aggregation of knowledge breaks down.

**On Friday, Deputy Attorney General Todd Blanche said the U.S. Department of Justice released more than 3 million pages under the Epstein Files Transparency Act** after months of pressure and a missed Dec. 19 deadline, following a large redaction review by hundreds of DOJ lawyers. The trove includes photos, interview transcripts, emails, call logs, and court records, with victims’ identities and women’s faces redacted. Reporting has highlighted emails and documents involving Bill Gates allegedly seeking to cover up contracting an STD, Prince Andrew inviting Epstein to Buckingham Palace, Elon Musk expressing interest in visiting Epstein’s private island, and records showing the Government of Canada denied Epstein entry in 2018. Left-leaning coverage alleges political manipulation, calling the release a “brazen cover-up” that “erases tips” involving President Trump, while right-leaning outlets stress the files show no criminal or inappropriate conduct by Trump and cite Epstein’s reported “disdain” for him. The Justice Department says the released information has not been verified.

**That detailed analysis is exactly why I rely on Ground News.** Instead of taking any single narrative at face value, Ground News helps you step back from the noise and see how the same story is being shaped across the media landscape.

Here’s why I recommend it:

- **See the full picture:** Compare how left, center, and right sources cover the same story
- **Reveal blindspots:** Instantly see what one side covers and the other side ignores.
- **Dig deeper:** See insights including headline comparisons, outlet reliability, and even the ownership behind publications

If you care about cutting through narrative spin and seeing the full picture, **Glenn Show readers can get 40% off the unlimited access Ground News Vantage plan** at **[ground.news/glenn](https://ground.news/glenn)**.

**IV. Dynamics: When Candor Appears—or Disappears**

Public discourse unfolds over time, so we need to understand the dynamics. Let us consider the role played by the various parameters in this situation.

As polarization increases, persuasion probability declines. If an audience approaches a contested issue with strong priors and moral commitments then, from a speaker’s perspective, the expected benefit of candor falls. At the same time, polarization magnifies reputational risks. Speech that might once have been heard as analytic comes to be heard as partisan or hostile. The expected cost of being perceived as morally deviant rises. These two effects reinforce each other.

A second dynamic involves audience beliefs. As self-censorship spreads, discourse grows more uniform and observers wrongly infer consensus—an inference that feeds back into the system, further discouraging dissent. Silence today produces greater silence tomorrow.

A third dynamic is reputational hysteresis. Moralized penalties can be sticky. Once a speaker is classified as a moral deviant, that classification can persist. Anticipating this durability, actors become especially cautious early on since prevention is easier than repair. So truthful revelation becomes more likely whenever institutions lower misclassification costs, increase persuasion probability, and provide protected channels for dissent—due process, norms of charitability, anonymity, structured debate, editorial independence, and spaces where disagreement can be expressed without immediate moral sorting.

These dynamics suggest a clear empirical implication. Wherever moralized reputational costs are high and persuasion is unlikely, we should observe patterned silence, ritualized speech, and the withdrawal of cautious dissenters. The following cases are not illustrations chosen for rhetorical effect. They are domains in which the model’s conditions are unusually strong, and therefore its predictions are unusually visible.

**V. Applications**

**Race in America**

Let me begin with the American discourse on race, because it is here that the dynamics I have been describing are most familiar to me, and are most fraught. A key question in this discourse is why racial inequality persists. In this domain speech is saturated with moral meanings. Claims about inequality, education, crime, family structure, or historical responsibility are rarely heard simply as attempts to explain social outcomes. They are taken also as signals of moral orientation—of sympathy or indifference, solidarity or hostility, compassion or disdain. For many audiences, answers to that question relying on structural causes are regarded more favorably than accounts emphasizing cultural factors. Speakers adapt accordingly—many by holding their tongues.

Notice what follows. The silence that emerges in this domain is not random. It is not evenly distributed across viewpoints. It clusters around claims that can be interpreted—fairly or not—as aligning with a stigmatized position. Many who think culture matters remain silent. Crucially, the fear driving that silence is not being wrong. Scholars are accustomed to being wrong. It is a fear of being misread. The speaker worries not so much about rebuttal, but about being assigned a moral identity from which there is no easy return—that is, being thought of as a racist.

The consequence is a familiar pattern. Public discourse becomes saturated with expressions of concern, solidarity, and moral commitment, even while causal analysis grows thinner and more repetitive. Certain explanations—involving bias and discrimination—are endlessly rehearsed, not because they are compelling, but because they are safe. Other explanations—involving behavioral responses, social norms and peer effects—quietly disappear from public view, though they remain widely discussed in private. The range of acceptable arguments narrows, although disagreement quietly persists.

To be clear, the problem here is not moral concern as such. Moral concern is unavoidable and justified. The problem is sequencing. When moral judgment precedes and then constrains causal inquiry, reputational risks come to outweigh epistemic incentives. Learning stalls. Culture comes to be under-appreciated in the discourse about racial inequality and the model predicts this biased outcome regardless of the substantive merits of the case. For if the audience takes it as a sign of moral virtuous to put structural ahead of cultural factors when accounting for persisting racial disparities, speakers discussing this issue will react to the social incentives created thereby.

Yet, here’s the truth: We cannot understand racial inequality if we refuse to consider all possible causal mechanisms. Culture, incentives, history, norms, policy, family, markets, behavior, bias—all warrant consideration. None should be taken to be off-limits. Genuinely moral argument must begin with the world as it is, not with the world we wish existed, or the one our expressive norms permit us to acknowledge. The self-censorship I’m decrying here inclines us toward a morality of symbolism—of performance that avoids uncomfortable facts—of social conformity masquerading as moral clarity. The appearance of righteousness crowds out the harder work of genuine ethical reflection. If we are guided by what we think is safe to say, not by what we think is true, we end up with an ethical discourse that is sentimental but unserious.

In this case, as the model suggests, the reputational cost of being misclassified as a racist is high, and the probability of persuasion on the points in contention comparatively low. To shift this imbalance, one could try to create formal spaces insulated from moral judgment and devoted solely to causal inquiry. Imagine standing analytic units—within universities, policy agencies, or serious news organizations—that are charged with answering empirical questions about racial disparities and prohibited from making policy recommendations. Its findings would be issued under institutional not individual authorship. Such a design could lower the cost of candor and make fully truthful revelation these sensitive issues more feasible to attain.

**Academic Life**

This reputational incentive calculus operates with force inside of academic institutions, even as universities understand themselves to be sites of open inquiry and disciplined disagreements. But they are also reputational ecosystems where careers depend on peer evaluation, hiring decisions, promotion, funding, and institutional support. As such, the cost of being morally misclassified can be substantial. The foremost moral fault line in this environment is that which separates social justice reform criticism from traditional political conservatism. The latter is a morally disfavored identity for many academic audiences.

Faculty members and graduate students learn the contours of this landscape quickly. They observe which questions provoke discomfort, which lines of inquiry attract controversy, which colleagues become isolated, and which arguments quietly fade away. No formal censorship is required. People internalize the reputational map and adjust their behavior accordingly. When deliberating about hiring, promotion, or public statements, certain concerns are voiced openly; others remain unspoken. People sense when raising a doubt will be read not as intellectual rigor but as ideological deviation. Over time, this shapes who speaks, who advances, and which kinds of arguments circulate. The result is uniformity—not of belief, but of expression. Disagreement moves underground. Public consensus hardens, not because it has been tested and survived, but because it has not been tested at all.

The problem worsens when conclusions become reputationally legible in ways that overwhelm epistemic method. The obvious institutional corrective is to reverse that weighting. But academic freedom cannot be sustained by rhetoric alone. It requires mechanisms that make it credible that scholars will be evaluated on epistemic process rather than conclusions—hiring, promotion, and publication decisions anchored, visibly and securely, in research design, transparency, evidence, and engagement with counterarguments, while bracketing political or moral implications. Those institutions that succeed at this will reduce the expected cost of dissent from consensus views and thereby encourage participants to speak candidly.

Ironically, travails at the University of Austin (UATX, where I sit on an academic advisory board) illustrate this logic. Founded explicitly in opposition to the expressive conformity of elite academic institutions, it has, according to some recent accounts, struggled with concerns about acceptable speech within its own ranks. A recent *[Politico](https://www.politico.com/news/magazine/2026/01/16/civil-war-university-of-austin-bari-weiss-00729688)* [article](https://www.politico.com/news/magazine/2026/01/16/civil-war-university-of-austin-bari-weiss-00729688) by Evan Mandery reports that UATX, a private institution launched in 2021 with the ambition of fostering “fearless” inquiry and countering perceived orthodoxy in higher education, has encountered significant internal turmoil and reputational problems. It describes how UATX’s early promise of intellectual pluralism has been undercut by factional conflict and resignations among faculty and advisors. Several prominent board members and advisors, including figures like Steven Pinker and others identified with classical liberal commitments, dissociated themselves from the project, complaining that it drifted toward an ideological agenda rather than a genuine commitment to open inquiry. Some critics quoted in the reporting describe a governance atmosphere in which positions were enforced in ways that made dissent difficult, and where mandatory events or programmatic choices tilted sharply in one political direction. These controversies, leadership disputes, and departures of key figures have led to questions about UATX’s ability to sustain itself and fulfill its founding mission. I certainly hope these concerns are unfounded.

All of this may be ironic, but it is not paradoxical. Defining an institution by its opposition to an orthodoxy does not eliminate reputational incentives; it merely reshapes them. A new audience forms, with new expectations and new expressive risks. Unless the underlying incentive structure is altered, self-censorship can re-emerge under the banners of heterodoxy and purported free inquiry. The lesson here is sobering. Self-censorship is not an ideological pathology to be found mainly on the Left. It is a structural phenomenon. Any institution that allows moral identity to attach too tightly to heterodox conclusions will generate expressive distortions, regardless of its stated commitments. After all, sometimes the orthodox view will turn out to be the correct one, not because it is orthodox, but because it is correct. Whenever conclusions become reputationally legible in ways that overwhelm method, conformity rules and candor will be in short supply. No rhetorical commitment to free inquiry can overcome that logic. Only institutional arrangements that reward knowledge-producing process over the inferred morality of ideological position can.  

**Israel and Gaza**

Finally, consider the public discourse surrounding Israel and Gaza. Few contemporary issues combine moral intensity, historical trauma, identity politics, and geopolitical complexity to the same degree. As a result, the reputational stakes of speaking are exceptionally high. A scholar who wishes to discuss strategic dilemmas faced by Israeli leaders may worry that such discussion will be heard as endorsement. A scholar who wishes to emphasize Palestinian suffering may fear being associated with extremism. Journalists often frame stories with an eye toward minimizing backlash rather than maximizing understanding. Some students avoid protests and remain silent not because they are persuaded, but because silence feels safer than speech. Others ostentatiously display their solidarity with those they say are “oppressed” by mouthing slogans, the implications of which they hardly understand.

The debate over whether Israeli actions in Gaza after October 7, 2023, constitute a “genocide” is an *almost textbook* example of the dynamics I am describing. And it is especially useful because it shows the mechanism at work on both sides simultaneously, rather than mapping neatly onto a single ideological camp. Let me explain this carefully. That debate illustrates the mechanism I have in mind not because the term “genocide” is uniquely contentious (though it is!), but because of how its use restructures incentives for speech. The word “genocide” is not merely descriptive. It is juridical, moral, and identity-laden all at once. To apply it is not simply to make a factual claim about civilian casualties or military conduct. It is to place Israeli actions into a moral category associated with absolute evil and to imply a corresponding moral status for those who defend, justify, or contextualize those actions. Precisely because of that, the term functions less like a legal category and more like a classification device.

Now, let’s think about how this affects different speakers.

A scholar of international law or military ethics might believe, in good faith, that the legal threshold for genocide is extremely high, that intent is decisive, and that while Israeli actions may be brutal, disproportionate, or unlawful, the genocide charge is not analytically warranted. Under ordinary academic conditions, that would be a position to argue for—to test against evidence, precedent, and counterargument. But the scholar understands that publicly questioning the genocide claim may be heard not as a legal judgment, but as moral alignment. The concern is not that colleagues will dispute the reasoning, but that the scholar will be seen as minimizing Palestinian suffering, excusing mass violence, or acting as an apologist for atrocity. Once that interpretation takes hold, further clarification rarely helps. The argument is no longer about law; it is about who the speaker is. The rational response, for many such scholars, is therefore silence, extreme hedging, or withdrawal into purely technical language that avoids the central moral question altogether.

Now, let’s reverse the perspective.

Scholars or activists who believe that the scale of destruction in Gaza, combined with statements by Israeli officials, *does* justify the “genocide” label may nevertheless hesitate to use the term in certain institutional settings. They may worry that invoking it will lead to accusations of antisemitism, association with extremist rhetoric, or complicity with violence against Jews elsewhere. Here again, it is not rebuttal but reputational (mis)assignment—being placed in the wrong moral category—that carries lasting stigma.

So, what happens? Degradation of public discourse is what happens.

Some people invoke the term loudly and unequivocally, especially in activist contexts where reputational rewards flow in that direction. Others avoid it entirely, even when they believe the underlying conduct deserves condemnation in the strongest terms. Still others substitute adjacent language—“collective punishment,” “ethnic cleansing,” “crimes against humanity”—not because they have carefully ranked legal categories, but because those terms carry different reputational risks. Meanwhile, many observers—journalists, students, administrators—infer consensus or polarization from what they hear publicly, without realizing how much of the distribution of belief is missing from view. This is exactly the equilibrium logic I have been describing.

The word “genocide” becomes less a tool of analysis than a sorting device. To utter it, or not to utter it, is to risk being classified — not argued with but classified — into a moral camp. Once that is understood, speech behavior changes predictably. Journalists frame stories in ways that avoid the term while gesturing toward it or adopt it without examination to avoid backlash from activist audiences. University administrators issue statements that condemn suffering while carefully avoiding legal characterization. Faculty members discuss the issue freely in private seminars but avoid public forums. Students repeat slogans they do not fully understand because those slogans function as protective signals.

What disappears from view is sustained, good-faith argument about the meaning of “genocide” in international law, about the role of intent, about precedent, about proportionality, and about the tragic tradeoffs of asymmetric warfare—not because those questions are unimportant but because answering them publicly has become too costly. This is the crucial point: the collapse here is not due to moral disagreement, but to epistemic incompleteness.

When a term becomes so charged that using it or questioning it immediately assigns to the speaker a moral identity, the space for inquiry slowly but inexorably closes, to the point that public discourse no longer functions as a mechanism for learning. Instead, it becomes a mechanism for signaling allegiance. And that, precisely, is the phenomenon I am trying to illuminate with my theory of self-censorship. Once again, the model does the work. Information exists. Judgment exists. But the incentive to reveal it does not.

While the content differs dramatically across all three of these domains, the rhetorical structure is similar. When reputational penalties are large and persuasion is unlikely silence and expressive distortion follows. These are not simply failures of courage. They are equilibrium outcomes.

[Share](https://glennloury.substack.com/p/self-censorship-social-information?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoxMjMwNTgyMiwicG9zdF9pZCI6MTg4MTQ2MTQzLCJpYXQiOjE3NzE0MzkxMDgsImV4cCI6MTc3NDAzMTEwOCwiaXNzIjoicHViLTI1OTA0NCIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.ZQQz-SdECU-aZa4A7Brl9ahb-9APGRrJQw7kS1eqx0k)

**VI. Democratic Deliberation and the Collapse of Common Knowledge**

I will now step back from particular cases and ask what my argument implies for the institutions on which liberal societies depend. Those institutions most at risk from the dynamics I have described are precisely those where truthful revelation is an operational prerequisite rather than a moral aspiration. Universities, journalism, scientific communities, and democratic politics itself all presuppose that speakers sometimes give voice to things that are unpopular, uncomfortable, or disruptive. They rely on the availability of honest signals in environments where dishonesty or silence would often be safer. When those signals disappear, the institution does not merely become less admirable. It becomes less intelligible as the kind of institution it claims to be.

Consider universities once more. The idea of academic freedom is not ornamental. It exists because inquiry is fragile. When scholars anticipate that certain conclusions will be interpreted as evidence of moral deviance rather than intellectual judgment, inquiry narrows before it begins. Questions go unasked. Hypotheses go untested. Entire domains become thin, not because they are exhausted, but because they are dangerous.

The same logic applies to journalism. A free press is not merely one that operates without government censorship. It is one in which reporters and editors can pursue facts that complicate prevailing narratives without being punished for the implications of those facts. When reputational penalties attach to certain lines of reporting, the press does not need to lie. Omission, framing, and emphasis suffice. Over time, the public loses access not to opinion, but to reality.

Scientific communities may be the most vulnerable of all. Science depends on the willingness to report anomalous results, negative findings, and unwelcome conclusions. When pursuing certain questions and publishing the results carries a reputational risk that is unrelated to methodological quality, then the scientific record becomes selectively distorted—not through fraud, but through avoidance.

Finally, democratic deliberation itself is at stake. Democracy presupposes not just voting, but by discourses of persuasion by means of which citizens and representatives articulate reasons, revise views, argue over values and respond to evidence. When speech becomes primarily a signal of identity or allegiance, deliberation collapses into performance. People speak to be heard, not to be understood. Argumentation becomes ritual. Compromise becomes betrayal. This culminates in what can be described as the collapse of *common knowledge*, by which I mean not merely shared belief but a shared understanding about what others believe, and what they know that we believe. It is what allows societies to coordinate around norms, policies, and institutions without constant coercion. Once expressive distortion becomes widespread, such shared understanding disappears. No one knows what others truly believe, so no one knows which norms are genuinely shared. No one knows whether an apparent consensus reflects agreement or fear. Public discourse becomes performative. Politics become symbolic. Debate becomes ritualized. And yet—and this is the most troubling part—from the perspective of each individual speaker, this outcome is entirely rational. Each person is responding sensibly to the incentives they face. This is a tragedy of the commons.

This brings us back to the deeper lessons of political economy. Social outcomes do not depend solely on intentions or values. They depend on incentives. Institutions cannot rely on courage alone. They must be designed so that candor is not prohibitively costly, and so that disagreement does not immediately collapse into moral judgment. There is no rhetorical escape from self-censorship. One cannot simply denounce the status quo and expect candor to flourish. What is required is something more demanding: institutional arrangements and cultural norms that make it safe to be misinterpreted, that allow disagreement without moral excommunication, and that protect speakers from durable reputational harm when they speak disturbingly but in good faith.

**Conclusion: Deviance without Stigma**

Let me close by returning briefly and deliberately to Kenneth Arrow. He taught us, perhaps more than any economist of the twentieth century, that social outcomes depend not only on individual intentions but on *conditions under which information is generated, transmitted, and aggregated*. He showed that when individuals are rational and well-intentioned, collective rationality can still fail—because information is imperfect, incentives are misaligned, and organizations place limits on what can be known and whether that knowledge can be effectively shared.

From this point of view, self-censorship is not a moral aberration. Arrow’s work in information economics emphasized that if incentives are misaligned, markets will fail. I have argued that *social incentives* —reputational sanctions, moralized norms, identity classification—can produce a similar kind of failure in domains far removed from markets. In this sense, self-censorship is a kind of informational diseconomy. Individuals bear the private cost of honesty, while the benefits of candid discourse are more widely shared. Discursive systems underproduce candor in many contemporary environments. As a result, the inputs into public deliberation are not honest beliefs at all. Expressions are strategically distorted by fear of misclassification. Public discourse may appear orderly, even though it is informationally hollow.

This brings us to the deepest implication of the argument. Liberal institutions depend not merely on freedom of speech in the formal sense but on *conditions under which speech can function epistemically*. They depend on shared understandings about what each other believes, on the possibility of disagreement without moral excommunication, and on the availability of honest signals even when sending them is uncomfortable. Those conditions collapse if self-censorship becomes equilibrium behavior. Common knowledge erodes. Apparent consensus loses meaning. Politics becomes symbolic. Debates become ritualized.

We lose access to valuable information when contrarian speech carries an excessive reputational cost. Institutions should insulate speakers from condemnation as persons based on their views, so what they believe can be heard. Universities, the press, and public forums serve their epistemic functions well only if they make room for deviance without stigma so disagreement can trigger argument rather than moral classification. Reform should not focus on enforcing a certain view but rather on lowering the private cost of honest dissent. Only then can collective judgments be informed by the full range of relevant experience. A society in which true belief is too costly to express is not merely ill-informed. It is incapable of self-correction.

Thank you.

[Share](https://glennloury.substack.com/p/self-censorship-social-information?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoxMjMwNTgyMiwicG9zdF9pZCI6MTg4MTQ2MTQzLCJpYXQiOjE3NzE0MzkxMDgsImV4cCI6MTc3NDAzMTEwOCwiaXNzIjoicHViLTI1OTA0NCIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.ZQQz-SdECU-aZa4A7Brl9ahb-9APGRrJQw7kS1eqx0k)