---
title: "Thread by @0x0SojalSec"
source: "https://x.com/0x0SojalSec/status/2021718688882413727"
author:
  - "[[@0x0SojalSec]]"
published: 2026-02-11
created: 2026-02-13
description:
tags:
  - "clippings"
---
WTF DeepMind.  They built an AI that doesn't need RAG, and it has perfect memory of everything it's ever read. It's called Recursive Language Models, and it might mark the death of traditional context windows forever. - Everyone's been obsessed with context windows like it's a dick-measuring contest. We have 2M tokens! No, WE have 10M tokens! Cool. Your model still forgets everything past 100K. They call it "context rot" and every frontier model suffers from it. - RAG was supposed to save us. Just retrieve the relevant chunks, stuff them in the prompt, problem solved. Except RAG is fundamentally broken for anything that actually matters. It can't handle tasks where you need to look at multiple parts of a document simultaneously. - Recursive Language Models flip the entire script. Instead of shoving 10M tokens directly into the model, you load the prompt as a variable in a Python REPL. The model writes code to search, slice, and recursively call itself on relevant snippets. It's so obvious in hindsight. - RLMs let AI do exactly that. The prompt isn't processed linearly it's an environment the model navigates programmatically. - The results are absolutely disgusting: GPT-5 base model on multi-document research: 0% (literally couldn't fit it) GPT-5 with RLM: 91% On information-dense reasoning: Base: 0.04% RLM: 58% That's not incremental improvement. That's a different capability emerging. - What's wild is the models figured out their own strategies without being trained for this. They started using regex to filter context without reading it all. Breaking tasks into recursive sub-calls. Verifying answers by querying themselves again. Zero special training. Just emergent behavior. - The cost situation is actually better than you'd think. Yeah, some trajectories get expensive because the model keeps recursing. But the median RLM run is cheaper than the base model. Why? Because it only reads what it needs instead of ingesting 10M tokens upfront. - This completely changes what's possible: - Analyzing entire legal codebases - Understanding million-line repositories - Synthesizing hundreds of research papers - Processing years of medical records All of these were theoretically possible but practically broken. Not anymore. - The researchers tested on GPT-5 and Qwen3-Coder with zero modification. No fine-tuning. No special training. Just give them a REPL environment and recursive access. That means you can use this approach right now with existing models. - Here's the kicker: current models are terrible at this compared to what's possible. They make dumb decisions. Repeat work. Sometimes compute the right answer and then... ignore it. Imagine explicitly training models to think recursively. We're still at the starting line. - Everyone's been focused on the wrong problem. The question isn't "how do we cram more tokens into context windows" It's "how do we let AI intelligently navigate unbounded information." RLMs just proved you don't need bigger windows. You need smarter navigation. paper : [http://arxiv.org/abs/2512.24601](https://t.co/8mcm19V2E1)