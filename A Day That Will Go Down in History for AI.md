---
title: "A Day That Will Go Down in History for AI"
source: "https://www.thefp.com/p/a-day-that-will-go-down-in-history"
author:
  - "[[By Tyler Cowen]]"
published:
created: 2026-02-09
description:
tags:
  - "clippings"
---
---

---

Last week brought a day that will go down in history. February 5 saw the release of Anthropic’s Claude Opus 4.6 and OpenAI’s GPT-5.3-Codex. That may not seem especially exciting to the non-expert eye, but behind these arcane names is a new reality.

What makes these new models so important is the fact that much of the programming work behind them was done by artificial intelligence rather than humans. [Anthropic insiders](https://x.com/slow_developer/status/2020064994101014727) [are claiming](https://x.com/bcherny/status/2015979257038831967?s=46&t=zHQCBTtfz3hXdhbfUsgEAg), for instance, that effectively 100 percent of the code behind their products is written by Claude itself. You can debate exactly how much human guidance and oversight goes into that, but other major AI labs all seem to be on [the same trajectory](https://openai.com/index/introducing-gpt-5-3-codex/). (Disclosure: I am on the Anthropic Economic Advisory Council.)

To those who build software or invest in it, the import of this is immediately clear. It’s already been clear that AI-aided programming will wipe out both jobs and companies. But everything that was true up to the release of these updates—the likely upheaval of white-collar work, the impending replacement of whole categories of companies—is more true now. What both Anthropic and OpenAI are doing is accelerating the development of the AI tools that will make it happen. Codex and Opus 4.6 are not just any AI models. There are models that are optimized to build more software—including, most importantly, future AI models’ tools. So from here on, AI is driving its own progress, and that progress will become *much* faster. Over time, that advantage will compound and accumulate.

OpenAI went from its last Codex release, on December 18, 2025, to what is widely acknowledged to be a much more powerful one in less than two months. This compares to frequent gaps of six months or even a year between releases. If OpenAI can continue at that rate, that means we can easily get four major updates in a year.

But the results from what people in the AI world call “recursive self-improvement” could be more radical than that. After the next one or two iterations are in place, the model will probably be able to update itself more rapidly yet. Let us say that by the third update within a year, an additional update can occur within a mere month. For the latter part of that year, all of a sudden we could get six updates—one a month: a faster pace yet.

It will depend on the exact numbers you postulate, but it is easy to see that pretty quickly, the pace of improvement might be as much as five to ten times higher with AI doing most of the programming. That is the scenario we are headed for, and it was revealed through last week’s releases.

Various complications bind the pace of improvement. For the foreseeable future, the AIs require human guidance and assistance in improving themselves. That places an upper bound on how fast the improvements can come. A company’s legal department may need to approve any new model release, and a marketing plan has to be drawn up. The final decisions lie in the hands of humans. Data pipelines, product integration, and safety testing present additional delays, and the expenses of energy and compute become increasingly important problems.

Nonetheless, it is now plausible to expect that AI model improvements will come several times faster than you might have been expecting, given immediate history.

Many casual users of AI will not notice big changes because the models they already are working with are so good. They are already fully capable of resolving many of the questions that come up in everyday life, like queries about facts or recent history—and many that are well outside ordinary situations, like [solving math-contest problems](https://www.thefp.com/p/in-a-top-math-contest-the-cheaters).

If you were planning on a career as a programmer, expect the job to evolve into something more akin to providing guidance and integrating and securing systems, rather than typing code.

Where the advance really matters is for advanced programming tasks. If you wish to build your own app, that is now possible in short order. If a gaming company wants to design and then test a new game concept, that process will go much faster than before. A lot of the work done by major software companies now can be done by much smaller teams, and at lower cost. Improvements in areas such as chip design and drone software will come much more quickly. And those advances filter into areas like making movies, in which the already-rapid advance of AI will be further accelerated.

Another upshot is that if you were planning on a career as a programmer, expect the job to evolve into something more akin to providing guidance and integrating and securing systems, rather than typing code. Many types of programming jobs that were recently common are already beginning to fade.

As Anthropic AI researcher Sholto Douglas has pointed out, these advances in software bump up against the limits of the physical world; they do not bring us, as Douglas says, to “ [limitless physical abundance](https://x.com/tbpn/status/2019585837038809228).” So one implication of this self-improving AI is that we could end up saturated in software and software-related advances and be all the more constrained on the physical side of our existence. For instance, as quality chip design accelerates, the value of chip factories will increase in tandem. But how quickly can we build such factories? A variety of non-software constraints will kick in.

The optimistic scenario is that advances in software create greater urgency and profitability for physical construction. If software can put more abilities in the hands of robots, there will be increased investment and innovation in robotics in ways that will increase physical production and, ultimately, human well-being. How smoothly and rapidly that process will go remains a matter of speculation. We can at least say that the probability of other rapid breakthroughs in tech, including physical tech, has gone up.

The downside is that all of the people who are behind in understanding the import of AI advances are now all the more behind. That may make social and political adjustment harder to pull off in the requisite time frame.

If there ever was a time to catch up, it is now.

[

](https://substackcdn.com/image/fetch/$s_!Fed0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe531bfcf-3901-49ac-92c0-7da55f7a9001_1320x30.png)