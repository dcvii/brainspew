---
title: "Higher education and AI in late 2025/early 2026"
source: "https://aiandacademia.substack.com/p/higher-education-and-ai-in-late-2025early?publication_id=1692672&post_id=183403287&isFreemail=true&r=7br8e&triedRedirect=true"
author:
  - "[[Bryan Alexander]]"
published: 2026-01-26
created: 2026-01-26
description: "Another scan of developments aimed at the new year"
tags:
  - "clippings"
---
### Another scan of developments aimed at the new year

Greetings from [winter storm Fern](https://en.wikipedia.org/wiki/January_2026_North_American_winter_storm), dear readers. I’m writing this from the Washington, DC area where around six inches of snow descended, followed by six hours of a kind of freezing drizzle. Hours of using shovel and snow-blower have made up for the gym being closed today, along with most of the local economy. Hopefully electricity holds out long enough for me to share this newsletter with you all.

In this freezing context, I’d like to return to examining what’s been happening recently with higher education and AI. Quite a lot has been going on over the past few months.

I’ve broken up what follows into several categories: AI, teaching, and research; scholarly publication and libraries; critiquing and opposing AI; general observations and research; final reflections.

(If you’re new to this newsletter, welcome! This is one of my scan reports, which are examples of what futurists call [horizon scanning](https://en.wikipedia.org/wiki/Horizon_scanning), research into the present and recent past to identify signals of potential futures. We use those signals to develop trend analysis, which we can use to create glimpses of possible futures. On this Substack I scan various domains where I see AI having an impact. I focus on [technology](https://aiandacademia.substack.com/p/ai-tech-developments-in-late-2025), of course, but also scan [government and politics](https://aiandacademia.substack.com/p/a-scan-of-ai-and-politics), [economics](https://aiandacademia.substack.com/p/the-autumnal-ai-economy), and [education](https://aiandacademia.substack.com/p/higher-education-and-the-world-prepare), this newsletter’s ultimate focus.

It’s not all scanning here at AI and Academia! I also write other kinds of issues; [check the archive](https://aiandacademia.substack.com/archive) for examples.)

![](https://substackcdn.com/image/fetch/$s_!HP68!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94e6afe8-8c94-42c6-888d-fe615b0a9bed_1024x1024.png)

Midjourney on “academics doing scholarly research with AI”

## AI, teaching, and research

Over the past few months I’ve seen many stories of academics using AI for teaching and research purposes. Purdue University (Indiana) did both, [announcing](https://www.purdue.edu/newsroom/2025/Q4/purdue-unveils-comprehensive-ai-strategy-trustees-approve-ai-working-competency-graduation-requirement/) it would expand [its AI efforts](https://www.purdue.edu/ai/). On the teaching side, all students will need to achieve “AI working competency” to graduate. What does this entail? The provost will lead departments along these lines:

> the goal of this requirement will be to ensure that, from exposure and awareness to skill-building and problem-solving mastery, Purdue students possess job-ready skills and critical thinking competencies to:

> *Understand and use the latest AI tools effectively in their chosen field(s)*, including identifying the key capabilities, strengths and limits of AI technologies, as well as ways that AI can transform existing methods, processes and tools
> 
> *Recognize and communicate clearly about AI use, decisions and limitations*, including developing and defending decisions informed by AI-driven insights, as well as recognizing the presence, influence and consequences of AI in decision-making
> 
> *Adapt to and work with future AI developments effectively and continually*

Interestingly, Purdue doesn’t use the term “literacy.” On the research side, Purdue will support AI efforts in food systems, health, manufacturing, military, and transportation. There are also partnerships with Google, Apple, and local K-12 schools.

On a related note, Wayne State University (Michigan) is [launching](https://www.govtech.com/education/higher-ed/wayne-state-to-launch-institute-for-ai-and-data-science) an Institute for AI and DAta Science (AIDAS), focused on research. It seems to be small scale, however:

> Vice President for Research and Innovation Ezemenari Obasi said the institute would cost $200,000 over three years and would be funded by the Division of Research and Innovation. After that, he said, the institute was expected to find other sources of funding.

A Universität Zürich (Switzerland) team is starting [an interesting project](https://github.com/DGoettlich/history-llms), using open source AI to produce new LLMs for one particular subject area:

> A family of 4 billion (B) parameter large language models (LLMs) based on the Qwen3 architecture trained *from scratch* on 80B tokens of historical data up to knowledge-cutoffs ∈1913,1929,1933,1939,1946, using a curated dataset of 600B tokens of time-stamped text

At a similar if smaller scale, an American college student [built](https://arstechnica.com/information-technology/2025/08/ai-built-from-1800s-texts-surprises-creator-by-mentioning-real-1834-london-protests/) a small language model trained only on 19th century British texts.

Stanford University has been very energetically working on AI. One faculty team [developed a new way of training AI visual capabilities](https://dense-functional-correspondence.github.io/). Their method focuses not on recognizing objects so much as the functions of those objects. The authors foresee applications in robotics. A different Stanford effort is [using AIs to build virtual scientists to work in virtual labs](https://med.stanford.edu/news/all-news/2025/07/virtual-scientist.html). A third deployed AI to [design viruses](https://www.nature.com/articles/d41586-025-03055-y), from the genome up.

Across the country, a group of Harvard University researchers [published](https://hms.harvard.edu/news/new-ai-tool-pinpoints-genes-drug-combos-restore-health-diseased-cells) on an AI application they named PDGrapher, which would help generate new medications. Its code is [freely available on Github](https://github.com/mims-harvard/PDGrapher). A University of Virginia professor wrote up his experiments with [using AI agents to help academics conduct economics research](https://www.nber.org/papers/w34202).

Back to the learning world, one of the founders of the learning management system/virtual learning environment industry, [Matt Pittinsky](https://en.wikipedia.org/wiki/Matthew_Pittinsky), wrote up [his thoughts for how AI might change the LMS/VLE](https://onedtech.philhillaa.com/p/lms-at-30-part-2-learning-management-in-the-ai-era). Briefly, he sees AI powering a massive new feature set around personalized learning, which will become the lion’s share of the LMS. He also envisions chatbots becoming the interface through which instructors create and redesign classes in the LMS.

A Georgia State University - Perimeter College professor described an [interesting use of AI](https://michellekassorla.substack.com/p/world-literature-with-ai-talk-to), teaching students to prompt a chatbot to simulate a conversation with an ancient literary character.

MOOC provider Udemy [announced](https://www.businesswire.com/news/home/20251215226900/en/Udemy-Introduces-AI-Powered-Microlearning-to-Evolve-Skills-Mastery) new AI functionalities for its online classes. It looks like a range of tools or actions:

> ***Instructor AI tools** that will enable instructors to transform their trusted course content and underlying learning objectives into interactive microlearning activities.*
> 
> ***Adaptive, AI-sequenced experiences**, using a mix of short videos, quizzes, and other instructional and active learning content.*
> 
> ***Instructor-validated quality**, allowing learning content to remain practical and grounded in real-world expertise.*
> 
> ***Context-aware interactions**, enabling AI-enhanced responses informed by learners’ background, goals and motivations.*
> 
> ***Expanded opportunities for instructors**, welcoming both existing Udemy instructors and new creators who specialize in short-form, interactive learning experiences.*

Some of those echo Pattinsky’s views, like building in AI as part of instructor course development. Adaptive experiences and context-aware interactions suggest personalization.

![](https://substackcdn.com/image/fetch/$s_!mKFK!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3940789e-3fbb-4b76-9130-fe6447d49c05_1024x1024.png)

Another Midjourney take on “academics doing scholarly research with AI.”

## Scholarly publication and libraries

On the scholarly publication side, an MIT team [surveyed](https://scholarlykitchen.sspnet.org/2025/08/12/guest-post-who-controls-knowledge-in-the-age-of-ai-part-1/) hundreds of academic authors for their views on using their material to train AI. The results are quite nuanced and worth digging through ([here’s a second part](https://scholarlykitchen.sspnet.org/2025/08/13/guest-post-who-controls-knowledge-in-the-age-of-ai-part-2-recommendations-for-stakeholders/) with advice). We can identify some highlights: around half of authors open to formal partnerships with AI firms; a widespread demand for attribution; much anxiety and many questions.

Along these lines, Northeastern University dean and history professor Dan Cohen [described a project](https://newsletter.dancohen.org/archive/the-librarys-new-entryway/) that combines a local Model Context Protocol (MCP) server and the Claude AI service into a plugin which aims to provide students with an accessible entrance into large scholarly databases. For example,

![A results page for a query in Claude about the Erie Canal, with neat sections on the different subtopics.](https://substackcdn.com/image/fetch/$s_!s8b0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3b1e22f-09d1-4e27-86f5-c5230f259325_960x1677.jpeg)

A results page for a query in Claude about the Erie Canal, with neat sections on the different subtopics.

(Dan also offers the term “LAG, or library-augmented generation.”)

## Critiquing and opposing AI

Conversely, there were many cases of academic research and institutions critiquing or opposing AI over the past few months. Two University of Sheffield (Britain) professors found that ChatGPT consistently [refuses to recognize](https://blogs.lse.ac.uk/impactofsocialsciences/2025/09/23/chatgpt-is-blind-to-bad-science/) when a scholarly paper has been retracted or debunked. Michigan State University’s extension program is casting itself in opposition to AI, [launching](https://bridgemi.com/quality-life/in-world-of-ai-michigan-state-university-extension-bets-on-human-expertise/) “a [campaign](https://urldefense.com/v3/__https:/u7061146.ct.sendgrid.net/ls/click?upn=u001.gqh-2BaxUzlo7XKIuSly0rC0sA2ifa1G8yJeuQZiZY9TpYuPtv6Az-2FHZiYrvNseYNW-2BRJe2LtHgCxYv-2By7KoAVcA-3D-3DYLwb_GYE5OY8oyYQgIEQgyZes7Bywo3vSU0O37Ghjog0MQx02HAb5YHaw0-2FIRXbQd0pU0NouMQZiffAy3PZZpiXgInyLca8DUMlADwWsqKvePfgjcMHnVgaTl-2FDV0wY-2BwWnkPBV-2Fa9W9Yj-2F0CKn2au-2BPldZyGQN3VUZFvYgjYH5Gy-2FIV-2FwnFGEoGFlwu-2BBOQCq2Vh1G47wXsHyBJR3fEyv2-2FBLKehlHQdJUYzBrt-2Bn4cnVhOt8XDM6spmvF-2F-2FFPOJNRtuuW-2BQyCuulV7iPtHeMQ8x9eGFEF0Y3N-2B-2B40xp1PWu3cuGk6c2IabJ8WQ1SYHPDNj-2FbReSij4U4hGGRypTM-2FRPtA-3D-3D__;!!HXCxUKc!x0nnT0dKNpx1XxQJHHLFUV2U34rBxklYCCvo3wTE1FqXI_WZ9iezGeAyX2448Kc7GL8rTRhHAvBZ8gKb6ccw$) to position MSU Extension as the antidote to AI slop.”

Some professors are turning to oral exams to mitigate the AI cheating problem, like [this writeup](https://www.businessinsider.com/nyu-professor-ai-oral-exam-mckinsey-memo-business-school-2026-1) of a New York University business professor. A San Francisco State University anthropology professor called on the California State University system to [suspend its relationship](https://www.insidehighered.com/opinion/views/2025/11/25/chatgpt-poses-risk-student-mental-health-opinion) with OpenAI, arguing that ChatGPT is doing serious mental health harm to students.

## General observations and research

On a broader level, Washington University professor Ian Bogost [determined](https://www.theatlantic.com/technology/archive/2025/08/ai-college-class-of-2026/683901/) that college and university students already have general access to AI in ways which changed their study habits, and that “plenty of professors are oblivious.”

> It isn’t that they fail to understand the nature of the threat to classroom practice. But my recent interviews with colleagues have led me to believe that, on the whole, faculty simply fail to grasp the immediacy of the problem. Many seem unaware of how utterly normal AI has become for students.

[A Chronicle of Higher Education survey](https://connect.chronicle.com/rs/931-EKA-218/images/Will%20AI%20Reshape%20the%20Value%20Proposition%20of%20Higher%20Ed.pdf?version=0&_gl=1*xjxw3c*_ga*ODM0ODMyNzAyLjE3NjczODQ2NTA.*_ga_WPH6W31S6Y*czE3Njc0OTMyNDIkbzMkZzAkdDE3Njc0OTMyNDIkajYwJGwwJGgw) found academics divided over the potential impact of AI on their institutions. Roughly a bit more than one half saw danger to the academy and viewed major structural action as called for, while around one third thought the danger overblown and change unneeded:

![](https://substackcdn.com/image/fetch/$s_!-o0u!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d03616b-4a0f-4932-8483-6f3e89164d4e_1578x1098.png)

![](https://substackcdn.com/image/fetch/$s_!C2dA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe323dea3-8474-4867-9b2c-f8141755ead7_1522x1188.png)

Readers may catch a couple of sentences in the report from me, where I aver that colleges and universities have little handle on the cheating problem.

## Some reflections

What do these stories tell us about academic responses to AI in late 2025 and early 2026?

Last summer I posted some thoughts on a similar question and some of those takes still hold. We are still seeing a wide range of academic uses across the curriculum, at multiple scales (single student up to entire university), a lot of collaborative projects. The deep divide over AI within the academy persists, with opposition and critique taking many forms.

Adding to those: I’m glad to see the open source projects from Zurich, Harvard, et al., both as in using open source tools and sharing results in the open. I’ve been calling for this kind of work for years.

I’ve very curious about Pittinsky’s LMS/VLE vision. It represents quite a transformation for that mature technology. Which established providers will take it up fully? How many startups will aim new projects at that vision?

There’s also that overarching sense of academia falling behind the revolutionary technology. The Chronicle survey and Bogost’s essay depict colleges and universities as institutions, and academic workers as individuals, struggling to keep up and respond well to the challenge.

Are you seeing similar developments at your institutions? Are there other academia and AI stories we should be discussing?

Now, on to other and promised newsletters. More coming up!

*(thanks to Bonnie Dede, Will Emerson, Karl Hakkarainen, Steven Kaye, Joe Essid)*