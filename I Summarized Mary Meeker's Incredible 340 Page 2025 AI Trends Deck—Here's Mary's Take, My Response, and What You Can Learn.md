---
title: "I Summarized Mary Meeker's Incredible 340 Page 2025 AI Trends Deck—Here's Mary's Take, My Response, and What You Can Learn"
source: "https://natesnewsletter.substack.com/p/i-summarized-mary-meekers-incredible?publication_id=1373231&post_id=164976114&isFreemail=true&r=7br8e&triedRedirect=true"
author:
  - "[[Nate]]"
published: 2025-06-02
created: 2025-06-02
description: "Yes, it's really 240 pages, and yes I really compressed it down, called out key takeaways, and shared what you can actually learn about building in the AI space based on 2025 macro trends!"
tags:
  - "clippings"
---


Yes, it's really 240 pages, and yes I really compressed it down, called out key takeaways, and shared what you can actually learn about building in the AI space based on 2025 macro trends!

*So Mary Meeker wrecked my weekend. She’s an incredible internet legend and she dropped a 340 slide report on AI (her first major public report in 5 years). I had to dig in.*

*Fair warning, there’s a lot here. I’ll cover the report itself. What I think of it as far as takeaways go, and give you more on Mary and reaction around the web toward the end.*

***Small note for free subscribers:** this is my monthly free deep dive report, hope you enjoy! Lots more good stuff like this weekly behind the paywall.*

## Part 1: The report itself

## Key Insights from Mary Meeker’s 2025 TAI Report on AI

In Bond Capital’s **[2025 Technology as Innovation (TAI) Report](https://www.bondcap.com/report/tai/#view/89)**, Mary Meeker – the famed tech analyst known for her Internet Trends decks – delivers a data-packed analysis of the ongoing AI revolution. The 340-page slideshow (titled *“Trends – Artificial Intelligence”*) emphasizes that the pace of AI development and adoption is historically unprecedented. Below is a summary of the report’s most important AI-related insights. It’s a bit dense, and there are lots of graphs!

## Top AI Trends and Takeaways from the Report

Meeker’s report backs up its bold claims with extensive data and charts. Key AI insights include:

- **Unprecedented User Adoption:** Generative AI has reached users at a **record-shattering pace**. For example, **ChatGPT hit 800 million weekly active users in just 17 months**, a user growth curve *“unprecedented”* in tech history. In under two years, ChatGPT accumulated about **365 billion annual searches**, a milestone that took Google 11 years to achieve. This meteoric rise highlights how quickly AI tools are being embraced worldwide.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/955ad487-be87-43a8-9151-4b3aa5ad029c_2028x1362.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:978,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:188620,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F955ad487-be87-43a8-9151-4b3aa5ad029c_2028x1362.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/3cb13960-3d6b-4122-bd57-ad9b1ac7873d_2050x1368.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:972,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:215491,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3cb13960-3d6b-4122-bd57-ad9b1ac7873d_2050x1368.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/dc227fa6-bf5b-4b34-a873-a0533cf93b1b_2050x1408.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1000,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:239323,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc227fa6-bf5b-4b34-a873-a0533cf93b1b_2050x1408.png%22,%22isProcessing%22:false,%22align%22:null})

- **Soaring Investment in AI Infrastructure:** The **“Big Six” U.S. tech giants (Apple, NVIDIA, Microsoft, Alphabet, Amazon, Meta)** spent **$212 billion on capital expenditures in 2024**, a **63% year-over-year jump**, largely pouring into AI chips, data centers, and cloud infrastructure. Meeker frames this as tech’s next platform bet – AI is prompting record investment to keep up with demand. Even chip innovation is racing ahead: NVIDIA’s latest 2024 Blackwell GPU achieves **105,000× greater energy-efficiency per AI token** than its 2014 predecessor, enabling far cheaper and faster model inference.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/04feabe1-4f45-461f-b210-9037249bf48f_2054x1378.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:977,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:327809,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04feabe1-4f45-461f-b210-9037249bf48f_2054x1378.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/0fe1c8e9-10e1-48b7-bb23-7ddb4f12b422_2034x1346.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:964,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:290938,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fe1c8e9-10e1-48b7-bb23-7ddb4f12b422_2034x1346.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/c45d0c4e-b125-47ca-9c96-a91f9ad11e29_2022x1384.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:997,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:226650,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc45d0c4e-b125-47ca-9c96-a91f9ad11e29_2022x1384.png%22,%22isProcessing%22:false,%22align%22:null})

- **Costs: High to Train, Plummeting to Use:** Training cutting-edge AI models is *extremely* capital-intensive – **up to $1 billion for a single model** – but the **cost of using AI (“inference”) has plunged by ~99% in two years** (measured per million tokens). In other words, it’s incredibly expensive to *build* frontier models, yet *using* AI services is rapidly becoming cheaper. This sharp cost decline for usage is enabling wider adoption, even as top-tier model development remains accessible only to well-funded players.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/4f777a9b-5492-4fec-a10d-9d251be43896_2044x1422.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1013,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:202931,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f777a9b-5492-4fec-a10d-9d251be43896_2044x1422.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/26f34908-7177-4c47-9d08-95d3dd864386_2028x1382.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:992,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:550616,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26f34908-7177-4c47-9d08-95d3dd864386_2028x1382.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/ec9e3eca-ec8b-4916-b80b-f0f88a3ecc37_2038x1344.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:960,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:269281,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fec9e3eca-ec8b-4916-b80b-f0f88a3ecc37_2038x1344.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/49956585-f0a1-4547-ba52-56b1183285c7_2048x1376.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:978,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:518546,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49956585-f0a1-4547-ba52-56b1183285c7_2048x1376.png%22,%22isProcessing%22:false,%22align%22:null})

- **Intense Competition & Rapid Imitation:** The AI arena has become a **fiercely competitive global “space race.”** Rival labs and even open-source communities are **matching new AI features at breakneck speed and often at lower cost**. Meeker notes that open-source and Chinese models are quickly catching up to proprietary Western AI models, eroding traditional moats. For example, she highlights that Chinese firms (like the hypothetical “DeepSeek”) are developing cheaper custom models that challenge U.S. leaders. Tech giants are also building their own silicon (e.g. Google’s TPU, Amazon’s Trainium) to accelerate AI – *“these aren’t side projects, they’re foundational bets,”* Meeker writes. The upshot is a **fast-follow environment**: innovations propagate globally in weeks, not years, keeping even early leaders on their toes.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/87c99eff-437c-42ee-aee4-916b6193a156_2042x1390.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:991,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:391186,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87c99eff-437c-42ee-aee4-916b6193a156_2042x1390.png%22,%22isProcessing%22:false,%22align%22:null})

- **Uncertain Path to Profits:****Enormous sums of VC and corporate money are flooding into AI**, but **financial returns lag behind the hype**. Meeker points out that even a premier player like OpenAI generated ~$3.7 billion in revenue in 2024 yet spent even more on computing power. Collectively, major AI labs (OpenAI, Anthropic, xAI, etc.) are valued around $400 billion and have raised $95 billion, but many operate at a loss. The report likens the current AI boom to a **commodity business with sky-high burn rates** – similar to how Uber or Tesla spent years unprofitable while scaling. This means **winners aren’t guaranteed**: it’s still unclear which AI ventures will achieve sustainable profits, as rapid innovation has come with **intense cash burn and price competition**. Meeker’s takeaway is that consumers benefit from falling costs and fast improvements, but investors must be cautious until true monetization power shakes out.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/39eac264-54ad-4a15-ac29-7fdb44f3996f_2024x1334.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:960,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:266974,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39eac264-54ad-4a15-ac29-7fdb44f3996f_2024x1334.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/dacacd10-3b64-44f6-a0cc-583e3956ec34_2044x1422.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1013,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:232987,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdacacd10-3b64-44f6-a0cc-583e3956ec34_2044x1422.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/6815a550-a323-4979-9006-4c37df9926cf_1990x1392.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1018,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:493194,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6815a550-a323-4979-9006-4c37df9926cf_1990x1392.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/8ebba224-1efa-48e7-8ca4-fe24ed5000d1_1998x1378.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1004,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:450824,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ebba224-1efa-48e7-8ca4-fe24ed5000d1_1998x1378.png%22,%22isProcessing%22:false,%22align%22:null})

- **AI Approaching Human-Level Abilities:** The **capabilities of AI models have made a leap toward human-like performance**. By early 2025, **73% of outputs from a prototype “GPT-4.5” were mistaken for human writing** by evaluators. In other words, test subjects could only tell 27% of the time that the text was machine-generated. This indicates we are nearing a point where AI can produce language nearly indistinguishable from a human’s – a milestone with big implications for education, media, and communication.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/ddc0cc0f-85fa-464f-89b3-d9810fa0201d_2058x1442.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1020,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:216441,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddc0cc0f-85fa-464f-89b3-d9810fa0201d_2058x1442.png%22,%22isProcessing%22:false,%22align%22:null})

- **Shifting Job Market & Skills:** AI is already reshaping the labor landscape. **U.S. job postings for AI-related IT roles have jumped 448% since 2018**, while listings for other IT roles **fell ~9%** in that same period. This dramatic shift shows how demand is **surging for AI skills (machine learning engineers, data scientists, prompt engineers)** even as traditional software roles evolve or shrink. In essence, tech talent needs to “pivot or perish” by upskilling in AI. Meeker’s report underscores that *every* knowledge worker may need to become conversant in AI tools, as companies prioritize AI expertise in hiring.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/5a2e5e6c-648b-4107-bbef-a04128733c83_2044x1372.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:977,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:350895,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a2e5e6c-648b-4107-bbef-a04128733c83_2044x1372.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/705db1d6-e231-4529-b620-dfde3811de70_2056x1400.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:991,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:655983,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F705db1d6-e231-4529-b620-dfde3811de70_2056x1400.png%22,%22isProcessing%22:false,%22align%22:null})

- **Real-World AI Adoption Across Industries:** Far from being confined to research labs, AI is rapidly penetrating everyday industries and services. Meeker gives striking examples: **Over 10,000 doctors at Kaiser Permanente now use an AI “medical scribe” assistant** to automatically document patient visits. In transportation, **about 27% of ride-hailing trips in San Francisco are already handled by autonomous vehicles** (e.g. Waymo and Cruise cars) – a remarkably high share in a major city. And in healthcare, the U.S. FDA has now **approved 223 AI-powered medical devices in 2023**, up from only 5 such devices in 2015. These data points illustrate **how quickly AI is moving from demo to deployment** – doctors, drivers, and many others are *already* working alongside AI, and that trend is accelerating.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/13fcea69-dc27-4521-af89-513bc9976a03_2032x1418.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1016,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:422434,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13fcea69-dc27-4521-af89-513bc9976a03_2032x1418.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/51eab2ad-b490-4573-9883-5fc5df207090_2058x1396.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:988,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:196304,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51eab2ad-b490-4573-9883-5fc5df207090_2058x1396.png%22,%22isProcessing%22:false,%22align%22:null})

- **Global AI “Space Race” and Geopolitics:** The report casts the rise of AI as a **geopolitical and economic game-changer**. One standout statistic: **China has more industrial robots in operation than the U.S. and the rest of the world combined**, reflecting how aggressively China is automating. Meeker suggests that *AI prowess may determine future global dominance*, as nations that lead in AI and automation could gain massive economic advantages. She notes that AI has ascended to a *“national strategy”* level priority for countries. In her words, *“AI leadership may determine geopolitical dominance,”* so the stakes extend beyond tech companies to entire economies and governments. This contrarian framing – thinking of AI innovation in terms of a **Sputnik-like race for world order** – emphasizes why the U.S., China, and others are investing so heavily. As one investor summarized, *the speed of innovation, talent distribution, and infrastructure built now will define who leads and who lags in the next era*.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/40eee42f-4787-4e9b-9ed1-3bd34d0e3f37_2052x1340.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:951,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:231648,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40eee42f-4787-4e9b-9ed1-3bd34d0e3f37_2052x1340.png%22,%22isProcessing%22:false,%22align%22:null})

## Mary’s Unconventional Perspectives vs. Mainstream Narratives

While much of Meeker’s AI analysis aligns with the tech industry’s excitement, **some of her emphases stand out as contrarian or unconventional** compared to mainstream narratives:

- **“Best of Times” Optimism for Education:** Instead of echoing common anxieties about AI in schools (cheating, misinformation, etc.), Meeker strikes an optimistic tone about **AI’s impact on learning**. She writes that after ChatGPT’s arrival, *“we have likely reached a generational, fast and furious change across education… This should be the best of times.”* This upbeat view – that AI will *enhance* learning and that universities can thrive if they adapt – is less gloomy than the mainstream. She **urges universities to lead in AI** rather than treat it as a threat, calling U.S. colleges *“bastions of technological progress”* that must partner with industry and government to drive innovation. It’s a **pro-innovation stance on academia** that runs somewhat against the grain of popular narratives focused on fear of AI displacing teachers or undermining student learning.
- **Focus on Speed over Caution:** Meeker’s report is unabashedly focused on **the breakneck speed of AI advancement**, repeatedly using the word *“unprecedented”* to celebrate that progress. Notably, she praises the bold moves that enabled this rapid growth – for example, highlighting that *Google “couldn’t have launched a product that hallucinated like OpenAI did” and that **startups can do crazy things***. This perspective implicitly **defends the “move fast and break things” approach** in AI. Mainstream discourse, by contrast, often criticizes AI products for their inaccuracies and calls for more cautious rollouts. Meeker’s take is unconventional in that she credits OpenAI’s willingness to launch an imperfect (occasionally hallucinating) AI as a **pragmatic gamble that paid off** – something large incumbents might not have dared.
- **Minimal Focus on AI Ethics/Regulation:** Unlike many public discussions of AI in 2023–2024, Meeker’s 340-page analysis gives **little attention to calls for AI pauses or heavy regulation**. The report centers on growth, competition, and opportunities, with **scant mention of AI’s societal downsides** (e.g. bias, misinformation, existential risk) that frequently headline mainstream media. One policy area she **does** stress is talent: Meeker argues the U.S. must continue attracting the world’s brightest AI minds, implicitly cautioning against restrictive immigration moves. *“America has to be a place where the brightest people in the world want to come… Our tech ecosystem would not be where it is today without a lot of first-generation immigrants,”* she told Axios. This pro-immigration, pro-talent stance contrasts with more protectionist currents in politics. Overall, her perspective is **optimistic and market-driven** – assuming that fierce competition and investment (not heavy-handed regulation) will address many issues, a view not universally shared outside of Silicon Valley.
- **Beyond the Silicon Valley Bubble:** Meeker deliberately highlights that **AI’s biggest impacts are happening outside of the usual tech hotspots**. She notes that *“the biggest changes aren’t coming from Silicon Valley. They’re showing up where software meets the physical world”* – in sectors like healthcare, agriculture, manufacturing. This emphasis is a bit unconventional because mainstream tech coverage often fixates on Big Tech companies or shiny consumer apps. Meeker’s report, by ranging from **the printing press to Roomba robots**, takes a broader historical and cross-industry view. It’s contrarian in reminding readers that **AI’s transformative power extends to “real economy” industries** and that innovation there may have the most profound societal effects, even if it’s less hyped in tech media.

## Part 2: My take

> ***TLDR: Mary is right that Generative AI adoption is exploding, but value accrues only where organizations align real-world problems AI’s actual strengths in workflows; every bigger claim demands commensurately bigger evidence.***

I break down this overall take into eight places where Mary and I diverge.

### 1\. Headline Adoption ≠ Uncomplicated Enthusiasm

ChatGPT really did race past every consumer-tech adoption record: eight hundred million weekly active users in just seventeen months is Apple-launch velocity without the hardware luggage. Mary Meeker’s slide is not wrong, and for mid-career operators it matters because it explains why board decks suddenly say stuff like *“Assume ubiquitous LLM literacy by Q3.”*

But nose-bleed user curves can fool you. When Pew Research puts a microphone in front of the same market, 52 percent of U.S. adults say they’re ***more concerned than excited*** about AI, and roughly four-fifths insist they “haven’t used it at work” (which again may not be true, since people lie in surveys).

Those two statements can co-exist because people under-report behaviour that feels rule-breaking (or résumé-threatening) yet still hammer ChatGPT for rewrite-my-email errands. If you look at TikTok, AI how-to clips do crazy engagement even as the comments fill with “this is how we lose our jobs.” Usage is feeding anxiety, not replacing it.

That fear-while-using dynamic shows up inside companies as **AI resistance** —the quiet decision to keep the LLM sandboxed in “safe” corners of the workflow. The sales VP mandates a call-summary bot; reps paste call notes in once a week so the dashboard lights up green, then type the real deal analysis in a private Slack thread. Engineering leadership buys twenty Copilot seats; half the team switches it off after the first auto-import fiasco. The metric you’re staring at looks like adoption, but as a leader you can’t figure out why you don’t *feel* the change.

Why does this matter for you, the person who has to green-light an AI budget before the next sprint review? Because **behavioural adoption ≠ organisational value capture.** Meeker’s chart tells you the surface area is there—hundreds of millions of people are now culturally comfortable opening an LLM prompt. What it doesn’t tell you is how much friction sits between that first prompt and repeatable, audited, P&L-visible output. If you mistake raw usage for strategic buy-in you will overspend on tooling, underestimate training time, and meet the CFO in a very unpleasant conversation six months from now.

The practical takeaway is to treat headline adoption as a *floor* rather than a forecast. Assume your end-users already use LLMs—some openly, many surreptitiously—and design roll-outs that convert that skunkworks energy into sanctioned, supportable workflows. That means:

- Re-instrumenting for **depth of use**, not just active users.
- Surfacing early wins where anxiety flips to confidence (e.g., “draft my Jira ticket” instead of “own the whole sprint plan”).
- Baking in guardrails and explainability so skeptics inside legal or compliance can say “yes” without losing face.

In other words, believe Meeker’s curve—but read the distrust hiding underneath it. Adoption at scale is real, enthusiasm isn’t, and your rollout plan has to bridge the gap.

### 2\. Where the Value Is (and Where It Isn’t)

Capital is no longer the bottleneck. 2024 saw the “Big Six” tech firms plough $212 billion into AI‐heavy cap-ex—a 63 percent jump year-on-year and, by Meeker’s own math, almost fifteen cents of every top-line dollar those companies earned. It’s the largest cash commitment to a single computing platform in history. **If AI were going to print money everywhere, we would already be bathing in the ink.**

Yet when you trace the money back to P&Ls, the yield is weirdly patchy. Stripe’s transformer trained on payment events pushed one fraud-pattern catch rate from fifty-seven to ninety-seven percent overnight and dropped straight to the bottom line. Kaiser Permanente’s ambient-scribe rollout frees three hours a week for twenty-five thousand clinicians; even at not-for-profit wage rates the ROI lands comfortably in eight figures. Nvidia’s sovereign-cloud business—the deal where a national telco pays to keep all tokens onshore—books up-front hardware revenue and locks in a decade of GPU service fees. These are **boring, contract-backed wins** and they live almost entirely inside B2B or infra workflows.

Contrast that with the consumer side. Two years after ChatGPT’s debut we still have…ChatGPT. Not because founders aren’t trying, but because incremental consumer features die the moment OpenAI or Google wedges them into the base model, and because consumers habit-stack: once you have a single chat box anchored on your phone, every new one feels like toggling search engines circa 2004. The economics look even harsher for venture-backed “GPT wrappers”—Meeker’s slide on collapsing inference costs is good news for end-users and hyperscalers, lethal for startups that mark up tokens for margin.

Inside the enterprise the story is different. Token deflation is a tail-wind, not a threat, **if** you own a lever the platforms won’t touch:

- **Data gravity** – proprietary or regulated corpuses (medical imaging, trade documents, tele-metrics) that outsiders cannot legally pull into pre-training.
- **Reward ambiguity** – industries where you can underwrite the outcome (fraud risk, quality-of-care scores, turbine uptime) and price on financial exposure rather than tokens. Risk pays!
- **Compliance bottlenecks** – any workflow where passing the audit *is* the moat, because you already paid that year-long legal bill and your faster-moving competitor hasn’t.

Meeker’s deck tallies the cap-ex and the cost curves; it doesn’t call out these friction points because friction isn’t visible from the thirty thousand foot level this deck operates at. But for operators these constraints define where the next tranche of value will land.

So as you plan the next two quarters, ask three questions Meeker doesn’t:

1. **What is my non-fungible input?** (Data, distribution, or domain liability.)
2. **Will cheaper tokens enlarge my margin, or compress it?**
3. **Can I prove ROI inside a budgeting cycle, the way Stripe and Kaiser did?**

Answer yes to all three and the money pouring into infrastructure will flow straight through your ledger. Miss one, and you’ll end up writing the polite post-mortem titled “Why Our AI Initiative Was Strategically Important But Commercially Premature.”

### 3\. Advanced Models ≠ Magic—Bigger Claims Need Bigger Proof

Every quarter the benchmarking headlines arrive: GPT-4o beats humans at X; o3 beats humans at Y; Gemini jumps backwards through hoops and discovers cancer drugs. I kid I kid. Even if we joke about overfitting on tests, the numbers are real—Meeker’s slide deck plots a straight-line ascent from GPT-3 to today’s frontier models—but the temptation is to treat that line as a direct proxy for business value. It isn’t, and the gap between benchmark brilliance and production impact widens the closer you work to messy, legacy workflows.

Think of it as a **gear-ratio problem**.

> **Benchmarks measure output per** ***token*****; businesses pay for output per** ***unit of context*****.** When the context is a single well-posed coding exercise, the ratio is almost one-to-one—Cursor users really do experience a 10× speed-up on fresh, green-field files. Move the same model into a 12-million-line monolith that predates React and half the juice evaporates.

With a context window that big, the LLM burns through its context window long before it can map the dependency tree, mis-types a function signature, and your diff fails CI. The benchmark gain hasn’t disappeared; it’s just geared down by integration friction, legacy debt, and the cost of human babysitting.

The same mismatch shows up in non-code domains. Feed Opus or o3 a pristine PDF of a sales contract and it extracts key clauses flawlessly; feed it a folder of half-scanned, half-redacted image files of documents and the recognition pipeline breaks before the reasoning engine even spins up. **Reasoning improvements don’t fix ingestion bottlenecks, memory limits, or real-world variance—they merely amplify them.**

This is why the loudest “agent” demos rarely survive contact with production. A frontier model can plan a fifteen-step code refactor in a sandbox, yet the moment you deploy it against live infra you need:

1. High-recall retrieval just to keep the relevant files in context.
2. A water-tight eval harness so the agent can’t merge broken code at 3 a.m.
3. A human escalation path for the 2 percent of cases the eval still misses.

You need to assume extra investment in evals and systems if you want to deploy production grade LLMs, particularly agents, in 2025. Ignore those extra checks and you’ll be in for a nasty surprise.

### 4\. “Just add agents” is the new “just add blockchain”—until the pager goes off at 2 a.m.

Google Trends confirms Mary Meeker’s hunch: in the first five months of 2025 global search interest in the phrase **“AI agent”** climbed more than a thousand per-cent. Venture memos now swap the word *copilot* for *autonomous agent* as though the re-branding alone tacks basis points onto IRR. The fantasy is powerful: point a frontier model at your workflow, let it plan its own tool calls, and come back to a finished outcome while the humans drink coffee.

And it can work! Companies from Kaiser to Bank of America are realizing real benefits to the tune of billions on real workflows. I mentioned it above, but Kaiser Permanente has a specialised agent that listens to a doctor-patient conversation, consults a taxonomy of visit types and ICD codes, then drafts the note in the EHR before the clinician stands up. Early pilots give roughly three hours a week back to twenty-five thousand practitioners—a monotonous administrative chore vaporised, and no one need worry about malpractice because the note still passes through the doctor’s eyes before signing.

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/a9d1f594-aa1a-4ec3-a48d-1bc306a944ec_2016x1432.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1034,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:576923,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9d1f594-aa1a-4ec3-a48d-1bc306a944ec_2016x1432.png%22,%22isProcessing%22:false,%22align%22:null})

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/e434aba2-6a74-49ee-9e34-e322a306a905_2030x1420.png%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1018,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:628034,%22alt%22:null,%22title%22:null,%22type%22:%22image/png%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe434aba2-6a74-49ee-9e34-e322a306a905_2030x1420.png%22,%22isProcessing%22:false,%22align%22:null})

Wayfair tells a parallel story in customer support: an LLM-driven triage agent classifies chat intent, suggests an answer, and escalates only the corner cases. Resolution time is down, CSAT is up, and the worst-case miss is an annoyed shopper, not a corrupted production database.

Those wins share three characteristics. First, the **scope is tight** —draft a single note, tag a single chat—so the agent’s entire working set fits into a context window or a tightly-bounded retrieval layer. Second, the **input schema is predictable**: medical conversations and ecommerce chats follow patterns the training data already knows. Third, the **down-side risk is capped**. If the scribe mishears a medication dosage the physician corrects it on review; if the chat agent chooses the wrong canned response the human rep still owns the ticket.

The moment you step outside that comfort zone your agent is liable to run off the road like a Porsche on after a late Saturday night. Long-running memory remains brittle; even with the fattest context windows you can buy, a multi-tool agent burns tokens faster than it solves problems and falls back on retrieval hacks that add latency and drop recall. Orchestration becomes a state-machine problem your staff now owns: someone must encode which function to call, when to loop, and how to back-off on rate-limit errors. Continuous evaluation is non-negotiable, because a QA pass at the end of a thirty-step plan is too late to catch a silent data mutation in step four. And no matter how glossy the pitch-deck looks, a real production agent still needs a human on-call who can read stack traces in the middle of the night. That staffing line item alone prices most mid-market vendors out of the “fully autonomous” dream.

**Scope is the only lever you wholly control.** When an executive asks for an agent, shrink the mandate until you can prove three things in a sandbox: first, the agent finishes the task 90%+ of the time without rescue; second, the remaining share of failures is bounded, auditable, and reversible; third, every miss surfaces fast enough that a human—not a cron job—decides whether to roll back or roll forward. Only after those proofs are green should you widen the mandate, and even then only a click at a time. Do that and the word *agent* becomes what Meeker’s deck really promises: a cheaper execution unit that lives inside the reliability envelope your ops team already owns. Skip the proofs, and the first night you leave the thing unsupervised will be the night you remember why cron jobs from 1998 still wake people up. Lol.

### 5\. Tokenisation Wins Battles—Tacit Knowledge Wins Wars

Transformers have turned the word *token* into a universal Lego brick. Once you accept that a payment event, a protein sequence or a LiDAR point-cloud can be sliced into discrete pieces and embedded just like words, almost every structured dataset in your organisation looks model-ready. Stripe proved the point recently: by tokenising the narrative of a transaction (“card-swiped → merchant → geo → device”), training a bespoke transformer, and looking for subtle fraud patterns—the company pushed a stubborn enterprise fraud-catch metric from 57 percent to 97 percent overnight. Meeker flags that case as evidence that “AI eats vertical data sources faster than people expect,” and for once the hype is justified.

But tokenization’s reach stops where tacit knowledge starts. The psychologist Michael Polanyi observed that “we know more than we can tell,” and that aphorism bites every time a model collides with the unsaid parts of work. Your team carries political context the model never sees: the CEO who isn’t really plugged in but still demands green-light status updates; the junior finance analyst who triages vendor emails because she knows which supplier will blow up if their invoice is delayed. None of that subtext appears in the source of truth, so no RAG pipeline can retrieve it, and no chain-of-thought prompt can reason about it. The result is what I call the **gear-slip**: the model predicts a perfectly logical next action that falls flat the moment it meets unwritten office reality.

Memory and privacy constraints amplify the gap. Even if you wanted to record every hallway conversation and ingest it as context, you would have to solve three unsolved problems at once: (1) the storage bill for petabytes of transient chat; (2) the legal nightmare of capturing material information your own compliance team hasn’t seen; (3) the technical task of pattern-matching across that fire-hose without a billion-token window. Workplace realities mean a lot of work will remain unspoken for a long time to come.

**What to do with this tension**

1. **Tokenise with intent.** Hunt for data streams where sequence truly implies meaning—sensor telemetry, claim workflows, audit logs—then build or buy a micro-model that speaks that dialect natively. That is where transformers still generate shocking delta.
2. **Map the tacit gap.** Ask: *Which decisions in this workflow rely on political context, unwritten norms or pure taste?* Flag them for human review up-front; don’t trick yourself into thinking a giant context window will erase them.
3. **Treat private context as a privilege, not an inevitability.** When legal or privacy teams block raw chat ingestion, assume they are doing you a financial favor. You have dodged an infinite-storage, infinite-liability bill. Channel your energy into the parts of the dataset you’re allowed to cache.
4. **Instrument everything you can, narrate the rest.** A note-taking agent that drafts a board packet is valuable; the board’s off-the-record reaction lives outside the model’s scope. Capture the first faithfully and accept the second belongs to a human.

The strategic mistake is to swing from “tokenization solves nothing” to “tokenization solves everything.” It solves the parts of the problem that **already speak in tokens** —and those parts are growing—but capturing those token streams isn’t going to replace the unspoken calculus of power, trust and taste that drives many workplaces. Builders who respect that boundary will keep their models sharp and their humans engaged. Those who ignore it will ship systems that draw the right conclusion on paper and still miss the reality.

### 6\. The Durable Human Edge: Judgment, Taste, and Time Horizons

Machines are sprinting; humans still win the marathons that matter. Meeker devotes several slides to the hiring boom around AI roles—postings for “AI-adjacent IT” positions are up 448 percent since 2018—but the deck stops short of explaining why those openings persist even as transformer accuracy climbs a power curve. The answer lives outside benchmark scores. Knowledge has become cheap; *judgment* has not. Model outputs can compress research, drafting, even first-pass designs to seconds, but the final call—ship or scrap, invest or walk away—still hinges on a felt sense for risk, opportunity, and political feasibility.

That sense is built the slow way. Seven-year thinking, the horizon Jeff Bezos swore by at Amazon, tends to outperform any quarterly cadence precisely because it captures compounding context: how sales, ops, finance, and regulation grind against one another through an economic cycle. The unspoken détente between infosec and product, the latent fear that the market might freeze next winter—none of this stuff appears in the token stream. A head of product who has watched five strategic resets and three re-orgs carries that texture the way an oak carries growth rings.

Taste is the flip side of judgment. When interface latency, copy tone, and error surfacing all converge on user trust, an LLM can propose five viable variants; only a human with aesthetic conviction can say, “That one feels right for our brand.” Meeker nods to this without labeling it: she highlights Jony Ive’s partnership with OpenAI as evidence that design will define the next hardware wave, yet the lesson applies everywhere. Builders love to adopt Linear over Jira not because Linear’s AI is bigger, but because the product *feels* frictionless. Taste is not a luxury flourish; it is a differentiation layer that tokens cannot undercut.

Persistence is the last unfair advantage. A frontier model can crank through a day-long coding sprint; it still falters on projects that unfold across quarters—refactors that touch twenty micro-services, partnerships that require six legal reviews, migrations that hinge on a vendor’s unspoken roadmap. Humans tolerate ambiguity over long timelines, reprioritize when market winds shift, and, crucially, remain curious after the tenth setback. That capacity is why Shopify and GitHub doubled down on junior “AI-centaur” hires: they want workers who metabolize tools quickly, then stay curious enough to drive cultural change for years, not weeks.

So the edge for mid-career builders is not in knowing the latest prompt syntax; it is in combining synthetic speed with human judgment, taste, and persistence. LLMs will keep gaining IQ points, but the ROI curve flattens without someone who can see around fiscal-year corners, decide which 5 percent of output to scrap, and shepherd the rest through compliance, politics, and design polish. If you cultivate that triad—judgment, taste, and seven-year endurance—the cheaper-and-smarter token flood amplifies your leverage instead of threatening your relevance.

### 7\. Economics and Policy: Why the Clock Is Ticking Faster Than the Rulebook

On price curves alone, AI is still operating in broadband time while most policy moves at railroad speed. Meeker’s slide on training economics shows the cost of building a frontier model falling by roughly one order of magnitude each year (today’s GPT-4-class system for under $20 million, GPT-3 money now buys you Alpaca-scale pocket toys). Meeker’s inference chart is even starker: tokens that cost $1.00 in 2022 cost about a cent today and will round to zero inside two more hardware cycles. For builders, that graph is *both* the good news *and* the booby trap. Every quarter you delay shipping, margin assumptions written in last November’s deck are out of date; every experiment that looked “too expensive” six months ago deserves a fresh run.

Meanwhile, regulators are discovering just how uneven global terrain can be. The EU is busy wrapping foundational-model audits, the U.S. banking agencies are floating “model-risk principles,” and half a dozen national governments—from Saudi Arabia to Korea—have jumped the queue by dangling tax holidays and GPU subsidies in exchange for sovereign-cloud installs. Nvidia’s sales heat-map in the deck is a geography lesson in real time: anywhere a telco or cash-rich ministry can host its own L40 racks, a “national-alignment” model is suddenly on the roadmap. That fragmentation explains why broad capability caps are a fantasy; you can’t pause a technology when every new data-centre ribbon-cutting creates a fresh jurisdiction.

The practical implication is that cost curves sprint while compliance gates jog. A Chief Risk Officer may need twelve months to sign off on a model that the infra team can train in three weeks, fine-tune in another three, and run for pennies. Builders have two levers to stay ahead of that mismatch:

1. **Audit-ready instrumentation from day one.** If you can’t surface what data the model saw, which tool calls it made, and how many tokens it burned, compliance will push your launch past the window where the economics were attractive. Cheap compute is perishable; don’t waste it waiting for an after-the-fact trace-ability retrofit.
2. **Distribution as insurance.** Because code is now the cheapest component, durable value hides in user relationships and proprietary datasets. When a new sovereign-model ordinance pops up, the team that owns the workflow—and the trust that rides with it—can swap a backend with minimal churn. The team that owns only an LLM prompt can’t.

So the clock you are racing is not just Moore’s Law in GPU clothing; it is the gap between hardware cadence and policy lead-time. Every quarter, tokens get cheaper and the regulatory thicket gets taller. Ship before the branches close overhead, instrument so you can prove you’re safe, and keep distribution close enough that a backend swap doesn’t erase your moat.

### 8\. Ground-Level Value: Where Meeker’s Physics Meet a Builder’s Reality

Mary Meeker has always been the internet’s best pilot at 30,000 feet, and this year’s deck is another master-class in macro vision. Her slides prove three things beyond argument: compute is compounding faster than anyone predicted, capital is willing to chase that curve indefinitely, and consumers are already dipping a billion fingertips into the interface. All of that is true. What those altitude readings *can’t* show is the topography that decides whether a company makes money while the curve steepens. That part lives closer to the runway, and it looks very different.

> **Value lives in the stack, not in the curve.**

A chip that renders a token for a tenth of a cent is wonderful, but it does not by itself close a customer ticket, file an insurance claim, or pass an FDA audit. The builder’s question is always, *“Where in this stack does a customer get value?”* Most often the answer is two or three layers above the silicon—at the pixel-level detail of a use-case that finally removes a pain the buyer feels every day.

> **Detail is what unlocks B2B.**

Spend ten minutes with an excellent AI-enabled application and you’ll realize the breakthrough is not “o3-class reasoning”; it is the fifteen edge-cases the team hunted down until the error rate slipped below the annoyance threshold or the finance team’s charge-back tolerance.

That surgical discipline is why B2B AI is scaling while consumer AI, outside ChatGPT itself, feels like a lottery: without strong distribution or brand gravity a new app has no room to iterate through the ugly details before it gets copied or drowned out. In business software, detail is defensible; in the consumer feed, it is ephemeral. It gets eaten by the consumer gravity well of ChatGPT.

> **Channel and brand still decide who earns the surplus.**

When code is virtually free and features commoditize in weeks, the durable moats look old-fashioned: a direct line to the budget owner, a renewal clause, a brand that signals “these people sweat the edge-cases so you don’t have to.” Linear wins because it *feels* better than Jira, not because it runs a proprietary model. Nvidia wins sovereign-cloud deals because ministries trust its roadmap, not because no one else can fab a GPU. Brand and channel are what let you keep value when the physics give it away.

> **Talent is the real scarcity.**

Meeker shows job postings rocketing, but she treats the supply of skill as an eventual function of capital. On the ground that assumption fails. You can’t run an agent in production without someone who understands retrieval fall-off, tool-calling schemas, and guard-rail evaluation.

Those people don’t materialize when you wire money to AWS; you have to hire them or grow them, and the market for LLM engineers, prompt architects, and evaluation-ops leads is white-hot. Companies that treat “AI talent” as an after-thought discover, six months in, that their proof-of-concept is stuck in red-team limbo because no one on staff can debug a wandering chain-of-thought. And training up teams (often the only option) is a very hit-or-miss process without LLM expertise inside the company.

**The AI acceleration headines are real, but value follows expertise, specificity, and trust.** Chips will keep getting faster, tokens cheaper, models smarter—that is the part Meeker measured. The part she could only hint at is where operating value shows up: in the teams that pair taste with domain chops, in junior “AI-native” hires who drag legacy organizations forward, and in leaders who are willing to grind a use-case until the last edge-case behaves. It’s the builders that will unlock that AI future in practice.

If you’re wrestling with where to take these takeaways, read Meeker’s slides for the direction of the industry, then drop to tree-top level and ask three questions:

1. **Which use-case can we own all the way to the pixel?**
2. **Which channel or brand asset will keep customers coming back when features leak?**
3. **Which people—present or newly hired—can carry the load that models still drop?**

Answer those with specificity and the macro curve becomes your tail-wind instead of a blur in the sky.

## A note on Mary Meeker: Tech Visionary and “Queen of the Internet”

Yes, if you haven’t heard of her you’re missing out!

- **Track Record:** Mary Meeker is a veteran technology analyst and investor renowned for her foresight. In the 1990s she rose to fame at Morgan Stanley with influential reports on internet companies, earning the nickname **“Queen of the Internet”**. She correctly predicted the potential of online giants like Google, Amazon, and Apple early on. Her annual **Internet Trends** reports, published from 1995 through 2019, became a **must-read in Silicon Valley**, crammed with insights on how the web and mobile were transforming business and society.
- **Investor & Bond Capital:** Beyond analysis, Meeker has been an active participant in tech’s growth. She joined **Kleiner Perkins Caufield & Byers** in 2010 to lead its growth-stage venture fund, where she backed future stars including **Facebook, Spotify, Airbnb, Slack, Ring, and Square (now Block)**. In 2018 she co-founded **Bond Capital**, a VC firm where she is General Partner. This dual experience as **both analyst and investor** gives her a unique 360° perspective on tech trends. When Mary Meeker speaks, founders and CEOs tend to listen, as she’s seen multiple innovation cycles up close.
- **Return to Publishing:** After a four-year hiatus from her famed reports, Meeker’s **2024 TAI report** marks her return to public trend-analysis, this time laser-focused on artificial intelligence. At 340 pages, *“Trends – Artificial Intelligence”* is effectively **her first major report since 2019**, signaling how important she believes AI’s impact will be. Co-authored with her team at Bond (Jay Simons, Daegwon Chae, and others), the TAI report extends Meeker’s legacy of data-driven storytelling. By quantifying everything from AI adoption rates to model costs and global talent flows, Mary Meeker is once again leveraging her **expertise and influence** to frame the conversation in tech. Given her history of accurate trend-spotting and the sheer breadth of this report, it’s likely to influence how executives, policymakers, and practitioners understand the state of AI today for the rest of 2025.

## Reactions from Other Experts and Media

Meeker’s return to publishing a tech trends report – and her focus on AI – has drawn significant attention in just the last couple of days. **Tech analysts, investors, and media outlets have offered their takes** on her report’s AI findings:

- **TechCrunch:** The tech press highlighted Meeker’s almost breathless focus on AI’s speed. *TechCrunch* noted that Meeker used the word “ **unprecedented** ” on **51 slides** to hammer home how AI adoption and innovation are unlike anything before. Their coverage emphasized her findings that **ChatGPT’s user growth was record-breaking and that AI costs are dropping precipitously**. They also echoed her point that **competition (including open-source and Chinese models) is driving down costs and matching features quickly**, citing her example of NVIDIA’s latest chip being vastly more efficient than its 2014 counterpart. In short, TechCrunch conveyed Meeker’s message that ***it’s not your imagination – AI really is accelerating everything*** (the very headline of their piece).
- **Axios (Dan Primack’s Q&A):***Axios* distilled **Meeker’s top takeaways** in an interview format. Primack underscored Meeker’s astonishment at **ChatGPT’s global growth – especially outside the U.S. (hello India)** – and the changing dynamics of tech distribution. The Q&A highlighted Meeker’s view that **Microsoft’s early investment in OpenAI was pivotal**, and that Google, despite its AI prowess, was constrained from launching a ChatGPT-like product due to reputational risks (hallucinations). She told Axios she doesn’t think OpenAI has an insurmountable lead, but she **expects ChatGPT to be around for a long time** and noted the *“intense competition the likes of which we’ve never seen”* now underway. Axios also drew attention to her policy angle on talent: Meeker gently criticized U.S. immigration restrictions that block AI talent, implying that winning the AI race requires remaining a magnet for researchers and developers worldwide.
- **Inside Higher Ed:** This outlet zoomed in on **Meeker’s education-focused insights**. It reported on her call for a *“mindset change”* in universities and for higher ed to *“take on an AI leadership role in partnership with government and tech firms.”* Inside Higher Ed noted Meeker’s belief that the next five years are *“consequential”* for academia and that institutions must *“find and sustain their differentiators… or risk losing market share in an AI-enabled world.”* The piece positioned Meeker’s 17-page *“AI & Universities”* mini-report (released in mid-2024) as a **wake-up call** to university leaders: adapt curricula, embrace AI in research/teaching, and uphold values in an AI era. This educational angle in Meeker’s work was well-received in higher ed circles as a **clear, if challenging, roadmap** for institutions to remain relevant amid AI disruption.
- **Investor and Analyst Commentary:** Many industry watchers seized on Meeker’s framing of AI as a **transformative “space race.”** PitchBook’s analysis (and posts by VCs on LinkedIn) highlighted her data showing how AI could *“reshape the world order.”* For example, investors noted Meeker’s stat that **China’s industrial robot installations now exceed those of the U.S. and rest of world combined**, seeing it as evidence of a national race for automation leadership. The consensus among these commentators is that Meeker’s report **“reads like a timestamp on a major shift already in motion,” not a distant forecast**. In other words, AI’s rapid deployment across industries is happening *now*, and Meeker’s trove of charts captured how far things have already progressed by 2025. This struck a chord with tech investors, who tend to agree with her that *the next tech giants (and leading economies) will be decided by who masters AI* – a narrative reinforced by her geopolitical and corporate investment data.
- **Media and Critic Reactions:** The tech media broadly praised Meeker’s comprehensive analysis and the return of her famous report. Outlets like *The Information* dubbed it “Meeker’s AI bombshell” and noted how it underscores AI’s breakneck trajectory. A few observers offered **critical nuance**: for instance, on forums like Hacker News, some argued that *not all of Meeker’s comparisons are one-to-one*. They pointed out that **Google’s early growth happened in a smaller internet era**, whereas ChatGPT launched into a world with billions online – context that might temper the “5.5× faster than Google” headline. Nonetheless, most coverage concurred with Meeker’s big picture: AI is **rewriting the tech playbook in real time**, and even seasoned analysts are amazed. The report has been described as both *“exhaustive”* and *“exhilarating,”* compiling a persuasive case that we are in a hyper-accelerated tech cycle driven by AI’s sudden maturity.

Phew! That’s a lot of info. If you’ve made it this far, well done! Hope this is a helpful overview of Meeker’s 340 page monster deck and reaction to it. As long as this article might have seemed, I promise you it isn’t close to 340 pages lol.

Enjoy, let me know your favorite takeaways below, and share this with someone who needs to see it!

![](https://natesnewsletter.substack.com/p/%7B%22src%22:%22https://substack-post-media.s3.amazonaws.com/public/images/76acdb57-59ab-463d-9fdb-604f901fbf00_1496x1352.jpeg%22,%22srcNoWatermark%22:null,%22fullscreen%22:null,%22imageSize%22:null,%22height%22:1316,%22width%22:1456,%22resizeWidth%22:null,%22bytes%22:433451,%22alt%22:null,%22title%22:null,%22type%22:%22image/jpeg%22,%22href%22:null,%22belowTheFold%22:true,%22topImage%22:false,%22internalRedirect%22:%22https://natesnewsletter.substack.com/i/164976114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76acdb57-59ab-463d-9fdb-604f901fbf00_1496x1352.jpeg%22,%22isProcessing%22:false,%22align%22:null})