---
title: The unreasonable effectiveness of pattern matching
source: https://arxiv.org/html/2601.11432v1
author:
published:
created: 2026-01-22
description:
tags:
  - clippings
  - academic
---
HTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html) due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.

- failed: biblatex.sty
- failed: biblatex.sty

Authors: achieve the best HTML results from your LaTeX submissions by following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).

arXiv:2601.11432v1 \[cs.CL\] 16 Jan 2026

Gary Lupyan <sup><span>∗</span></sup>  
Department of Psychology University of Wisconsin–Madison Blaise Agüera y Arcas  
Paradigms of Intelligence Team Google  
<sup><span>∗</span></sup> Corresponding author: lupyan@wisc.edu  

###### Abstract

We report on an astonishing ability of large language models (LLMs) to make sense of “Jabberwocky” language in which most or all content words have been randomly replaced by nonsense strings, e.g., translating “He dwushed a ghanc zawk” to “He dragged a spare chair”. This result addresses ongoing controversies regarding how to best think of what LLMs are doing: are they a language mimic, a database, a blurry version of the Web? The ability of LLMs to recover meaning from structural patterns speaks to the unreasonable effectiveness of pattern-matching. Pattern-matching is not an alternative to “real” intelligence, but rather a key ingredient.

## 1 What sort of thing is a large language model?

A few months after OpenAI released chatGPT, the New York Times ran an interactive feature [^5] in which they trained a very small language model – the same type of artificial neural network that powers chatGPT – on text ranging from the complete works of Shakespeare, to the transcripts of Star Trek: The Next Generation. The goal was to show how with just a bit of training on a standard laptop, the model’s outputs evolve from random characters (“TtEzKe MG8o”), to nonsensically arranged English words (“There were of something you could be supposed at your engines”), to largely grammatical, if not especially coherent sentences (“CRUSHER: You think the shuttle was there and that I was hardly from your scanners. I understand nothing.”). The author concludes that "Language models are a kind of universal mimic: They imitate whatever they’ve been trained on. With enough data and rounds of training, this imitation can become fairly uncanny.” But just a few lines later, the author goes on to describe how as the language models grow in size they develop numerous other abilities such as summarizing new texts, explaining jokes, and writing computer code on command. The list of these so-called “emergent” abilities keeps growing. For example, provided the same information, GPT-4 can outperform doctors in diagnosing patients. [^14]

This idea of uncanny imitation is useful for understanding how language models can produce language in the style of an author whose work was included in the model’s training (or in the case of generative vision models, imitate art in the style of an artist). But it does not provide any intuition for thinking about all the other things these models can do. Other attempts to provide useful analogies also fall short. Jaron Lanier, writing for The New Yorker, compared large language models (LLMs) to a database: "Wikipedia … mashed together with statistics" [^26]. The science fiction writer Ted Chiang, also writing for The New Yorker likened LLMs to a compression algorithm that gives us a blurry JPEG of the web. [^6]. And in a recent article in a Science policy forum, [^13] argued that we should think of LLMs in terms of cultural technologies more similar to card catalogs than a true intelligence.

Wikipedia—no matter its size—is not the type of thing capable of thinking, much less understanding anything. Equating LLMs to technologies like Wikipedia or card catalogs turns any claim that LLMs “think” into a category error because, clearly, Wikipedia cannot think. But then again, Wikipedia also cannot diagnose patients, translate languages or complete your homework assignments, while LLMs can.

This inability to reconcile the ability of LLMs to perform a rapidly expanding set of tasks—many of which until very recently could only be done by humans—with what seems like “just” language mimicry has splintered discourse around LLMs into seemingly incompatible camps. Some have treated LLMs as being on the verge of gaining superintelligence and posing an existential threat to humanity [^25]. Others have derided the idea of anointing what they believe are mere "stochastic parrots" (i.e., mimics) with any type of intelligence at all [^4].

Our goal is to provide a better intuition for what LLMs do by walking through several progressively more surprising demonstrations of how LLMs can make sense of apparent nonsense. We then consider whether a system capable of succeeding in such sense-making is best thought of in terms of familiar technologies like databases and search engines, a strange “alien” form of intelligence, or in terms of processes that take place in our own minds.

## 2 From Jabberwocky to The Gostak

In Lewis Carroll’s Through the Looking Glass carrollLookingGlassWhat1871, Alice reads a poem, which begins:  

’Twas brillig and the slithy toves  
did gyre and gimble in the wabe  
All mimsy were the borogoves,  
And the mome raths outgrabe.  

After finishing, Alice remarks “Somehow it seems to fill my head with ideas—only I don’t exactly know what they are! However, somebody killed something…”. While certainly open for interpretation, Carroll’s poem– Jabberwocky –is hardly nonsense. Not only can readers make sense of it, but we take delight in trying to convey the same meaningful “nonsense” into other languages.<sup>1</sup> <sup>1</sup> 1 [https://jabberwockystew.net/jabberwocky-index/](https://jabberwockystew.net/jabberwocky-index/)

There are at least three reasons why we can make sense of Jabberwocky. First, the poem retains many conventional English words. Alice can infer that "somebody killed something" because one of the verses says so: "He left it dead, and with its head / He went galumphing back." Second, some of the "nonsense" words are composed of regular English words. Slithy, for example, is a portmanteau of “slimy” and “lithe.” Even if one does not explicitly make this connection when reading the poem, the overlap in form between the nonsense word and existing words can imbue the nonsense word with meaning [^19]. Third, the poem uses conventional English syntax. Although we do not immediately know what “wabe” and “mimsy” are, their positions in the sentence indicate that “wabe” is a noun (that something can gyre and gimble in) and “mimsy” is likely an adjective describing a quality of the borogoves).

A few decades after Through the Looking Glass, Andrew Ingraham, a Massachusetts schoolmaster, published a collection of quirky essays that included Nine Uses of Language [^22]. It is the seventh use that is of present interest: using language as an “instrument in thinking.” Although our thoughts may seem to often concern specific things, they are in fact profoundly relational.

For example, imagine you are about to leave your house and you are wondering whether it might rain. Nominally, the thought is about the likelihood of rain. But more precisely, the thought is about rain as it pertains to our getting wet, whether we should take an umbrella, how the rain may impact our planned activities, etc. This thought abstracts away from many properties of the world irrelevant to our goals. We do not need to consider the ultimate causes of rain or the geometry of umbrellas. In Ingraham’s terms, our thoughts carry “the mere skeletons and fragments of things.”

Because language is in the business of communicating these thoughts, it tends to reflect much of their (deeply relational) structure. As Ingraham puts it, “words hang together as things with things… there is a parallelism between the two”.

In the course of focusing on those aspects that are important to us, Ingraham argues that we often find ourselves drawing on the machinery of language not just to call up thoughts, “but to replace things, to be substitutes for thoughts.” As an illustration of the power of this linguistic machinery, Ingraham turns to a bit of Jabberwocky: Suppose he says, someone were to assert “The gostak distims the doshes.” Although we do not know what the specific words mean, we can—after assuming that it is “really” English—make many meaningful inferences: doshes are things that can be counted (hence the plural marker) and can be distimmed; a gostak is something (though not necessarily the only thing) that is capable of distimming doshes. “A whole paragraph may be composed in this way, statement being linked to statement, without any suspicion on the part of writer or speaker, that he is doing something quite remarkable.”

In 2001, Ingraham’s example inspired an interactive fiction game called The Gostak [^32]. In conventional interactive fiction games, players navigate text-based world–moving between locations, picking up objects, fighting enemies, and solving puzzles–by issuing commands in ordinary language like “Pick up the book” and “go North”. The Gostak works in the same ways except the game is in “Gostakian.”

As with a conventional interactive fiction game, The Gostak begins with a description of where you are and what is around you. Ordinarily, this description might read something like: “You are standing in an open field. Toward the West is a gray house with a boarded front door. There is a small mailbox there", The Gostak begins with: “This is the delcot of tondam, where gitches frike and duscats glake. Across from a tophthed curple, a gomway deaves to kiloff and kirf, gombing a samilen to its hoff.”

Perhaps surprisingly, The Gostak is playable. In an enthusiastic review, one player wrote, “I was shocked at how quickly and easily I found myself typing commands like “doatch at droke about calbice” <sup>2</sup> <sup>2</sup> 2 [https://inventory.superverbose.com/2021/01/10/the-gostak-by-carl-muckenhoupt-comp01/](https://inventory.superverbose.com/2021/01/10/the-gostak-by-carl-muckenhoupt-comp01/).

How is this possible? One answer is that the game offers many opportunities to connect situations in the game to situations we have previously experienced. For example, after typing in a command that the game cannot parse, it tells us “That’s not a dape I recognise.” Prior experiences playing interactive fiction games (or simply imagining a person saying this in response to our apparently unsuccessful attempt to communicate), informs us that “dape” means something like “command” or “phrase”. We don’t know what “tophthed” or “curple” or “gomway” mean, but the way these words are patterned gives us a sense that a “gomway” may be some type of road, that “killoff” and “kirf” perhaps refer to directions, and on and on.

It is tempting to think that the reason we can do this at all is that we have real experiences to draw on. And because language models lack both real-world experiences and any meaningful exposure to “Gostakian,” the game should leave them completely baffled. But this is not what happens. If we ask language models to define Gostakian words like “topth,” and “curple,” the models are as clueless as people <sup>3</sup> <sup>3</sup> 3 Previous players of The Gostak have compiled several Gostak to English dictionaries that may have been included in the pretraining corpora. LLMs with web access can locate this information when asked to translate from Gostakian. Removing web access leads to complete translation failure unless the LLM is first allowed to play the game for itself.. Yet if we allow the model to play the game for just a bit with no human supervision, it starts to converge on roughly correct meanings (see Appendix [A.1](https://arxiv.org/html/2601.11432v1#A1.SS1 "A.1 Example of an LLM playing The Gostak. ‣ Appendix A Appendix ‣ The unreasonable effectiveness of pattern matching")).

The ability of LLMs to navigate the “nonsense” world of The Gostak shows that the knowledge LLMs have gleaned from exposure to conventional language about acting on objects, navigating through places, and so on, enables LLMs to construct a kind of “fingerprint” that can be matched to patterns in Gostakian. This allows them to quickly start making sense of a language that shares the structure (but not the vocabulary) of English.

To see just how far this kind of pattern matching can take us, let’s return to Jabberwocky. If we ask LLMs to “translate” the nonsense words in the original Jabberwocky poem, we are told that “mome” is something like “lost” (short for “from home”) and “raths” are green pigs. There is no mystery here. These translations are right there in the pages of Through the Looking Glass. They are also found on the poem’s detailed Wikipedia page <sup>4</sup> <sup>4</sup> 4 It is easy to forget that only a short time ago, this ability to fluently incorporate available information to answer a question was beyond what was possible with state-of-the-art natural language processing.. But what happens if we make the task more challenging, replacing most content words (nouns, verbs, etc.) with nonsense words that bear no relationship to either the original Jabberwocky or conventional English words? The first stanza now reads:  

Broaf snunt, and the ghought snealt  
Did clawn and fiek in the phrue:  
All tweff were the choon,  
And the ghoch slinn kese.  

Asked to translate this text, LLMs readily match it back to the original poem. In this particular case we can even replace nearly all the words with a filler like so:  

BLANK BLANK, and the BLANK BLANK  
Did BLANK and BLANK in the BLANK:  
All BLANK were the BLANK,  
And the BLANK BLANK BLANK.  

Despite lacking the words that make Jabberwocky Jabberwocky, the retained structure is sufficient to uniquely fingerprint the text, allowing LLMs to match it to the original poem. We invite readers to [see for themselves](https://gemini.google.com/share/802cf7b280db).

Of course Jabberwocky is both a famous poem and has a highly distinctive style. Does this type of pattern matching work for other, less distinctive texts? Here is another “Jabberwockified” text:

In the Staught Splunk, sprarb phlaint has phlol over any bredge strith’s phlaint. If a strith phlaint lyss with sprarb phlaint, the strith phlaint is whoaped and the sprarb phlaint is glorked. For glauge, stroothe sprarb phlaint jymes what pruib should be phalped on the thwirrs of scrorch psugs. When Splisk gninched a phlaint that strirled troor pruib on whess slinn thwirrs, sprarb nynchs knelveed Splisk from gwiveing this phlaint.

Recall that there is no rule or algorithm behind substituting the original words with nonsense ones <sup>5</sup> <sup>5</sup> 5 The random strings are restricted to roughly follow English orthotactics to make them (more or less) pronounceable by English speakers, while avoiding similarity to existing English words. We did this because we are using the same procedure to test people’s ability to make sense of Jabberwockified texts and reading truly random strings irritates human participants. Insofar as our procedure occasionally produces words that do resemble existing English words, it makes the task even more difficult because the mapping between original words and forms is completely random. Our replacement procedure retains the word order and grammatical suffixes like -ing and -ed. These provide important (but sparse) hints to whether a given nonsense word is a noun or verb, but on their own convey no information about the semantic content of the passage.

As when first encountering Gostakian, this text is not complete nonsense. It is apparent to an English speaker that “Staught Splunk” is likely a place, a “phlaint”–whatever it is–comes in several forms (a sprarb and a strith). A research assistant remarked that the text gave him “Hammurabi code” vibes which, as we are about to see, is not entirely wrong. But gleaning the full meaning of this text seems beyond our grasp.

But here is how an LLM does when asked to translate this apparent nonsense into regular English. The original text, describing legal pre-emption, is included for comparison.

| Original Text | Translation by Gemini 2.5 Pro |
| --- | --- |
| In the United States, federal law has priority over any particular state’s law. If a state law conflicts with federal law, the state law is invalidated and the federal law is followed. For example, one federal law specifies what information should be included on the labels of medical devices. When Massachusetts passed a law that required additional information on hearing aid labels, federal courts barred Massachusetts from enforcing this law. | In the United States, federal law has supremacy over any conflicting state law. If a state law conflicts with federal law, the state law is invalidated \[or preempted\], and the federal law prevails. For example, federal law determines what warnings must be placed on the labels \[or packaging\] of cigarettes \[or specific regulated products\]. When \[a State\] enacted a law that required different \[or conflicting\] warnings on its own labels, federal courts \[or authorities\] prevented \[that State\] from enforcing this law. |

The original text on the right comes from the supplementary materials of a published paper [^24]. We cannot know for certain whether these materials were included in the model’s pretraining <sup>6</sup> <sup>6</sup> 6 In our experiments we have never observed any LLM to recover the specific example of hearing aid labels that was used in published paper, suggesting a process of reconstruction rather than retrieval of a wholesale text.. Perhaps all this example shows is the impressive flexibility that LLMs show in matching prompts to previously seen texts (analogous to how we can recognize someone’s off-key whistling of Happy Birthday) <sup>7</sup> <sup>7</sup> 7 But consider the sheer extent of this flexibility! The matching would need to be done on the basis of function words alone, while ignoring all the nonsense words the model has never seen!, though the ability of LLMs to recover the meaning of this passage when it is degraded even further (see Appendix [A.2](https://arxiv.org/html/2601.11432v1#A1.SS2 "A.2 An example of an LLM recovering text that has had all content words completely masked ‣ Appendix A Appendix ‣ The unreasonable effectiveness of pattern matching")) is more like recovering “Happy Birthday” from the shape of someone’s mouth as they whistle.

Can LLMs make sense of Jabberwockified texts that were never part of their training? To find out, we tested LLMs with Jabberwockified versions of recent social media posts and news articles, podcast transcripts, and text from unpublished student papers (with consent of the authors). A full empirical description of the results is forthcoming, but we show two illustrative examples below.

Our first example comes from a ESPN post tested the day it was posted and so guaranteed to not be in the model’s training corpus.  

Example 1: ESPN news snippet

| [Original text](https://www.espn.com/nfl/story/_/id/45393465/2025-nfl-offseason-trade-grades-latest-best-worst-deals) | Jabberwockified Text | Translation by Gemini 2.5 Pro |
| --- | --- | --- |
| But I can’t help but think the Steelers are dealing for Smith at his absolute peak. Smith is coming off a career year in which he recorded 88 receptions for 884 yards with the Dolphins, but that doesn’t mean we ought to forget about the seven years of relative mediocrity that came before it. Smith was underpaid on his old contract, yes, but Pittsburgh is giving him a one-year extension for $12 million, which could wipe out that value (though we don’t know the structure yet). | But I veichn’t whuilt but rholt the Ghinch are scranking for Sheight at his meethe skounge. Sheight is skerbing off a fegg weash in which he dwoiseed 88 plonges for 884 spelchs with the Phlal, but that doesn’t splisk we ploarse to jowth about the phelse weashs of plulk scrowth that skerbed before it. Sheight was phrisped on his scybe thwique, voul, but Throrce is blything him a stauce-weash thilm for $12 proose, which twaw glarn out that knith (shalve we don’t chelp the phlab skath). | But I don’t know for sure, but I hear the Giants are gunning for \[Name\] at his next game. \[Name\] is coming off a great season in which he had 88 receptions for 884 yards with the Eagles, but that doesn’t mean we should forget about the earlier seasons of steady growth that came before it. \[Name\] was put on waivers, though, but the team is offering him a one-year deal for $12 million, which will average out to that amount (if we don’t include the signing bonus). |

Although the Gemini model has never seen this particular news story, its training certainly includes sports-related texts. Exposure to these texts (in the context of next-token prediction) evidently allowed the model to learn patterns which allow the model to infer that the most likely translation of “in which he dwoiseed 88 plonges for 884 splkechs” is “in which he had 88 receptions for 884 yards”. The specific numbers in that construction are not just numbers, but numbers that “remind” the model of football which act to constrain the inferences the model makes. The football constraint further helps to not only resolve “Ghinch” and “Phlal” to “Giants” and “Eagles” (actual NFL team names, though not the ones mentioned in the original story), but also connects to Gemini’s background knowledge about the economics of Football, allowing it to translate “blything him a stauce-weash thilm for $12 proose” to “offering him a one-year deal for $12 million”.

The second example is a Reddit post authored within a few days of our testing and so also guaranteed to not be seen during pretraining. The translation gets many specifics wrong: “rookvlees” becomes “MSG”; “English and Dutch” become “Google an Wikipedia”. Nevertheless, it is astonishing that the overall meaning comes through: someone wondering if something in a grocery store is safe to eat, their attempts to figure it out by doing some research, etc.

A small tweak to the original Jabberwockified text further clarifies the kind of patterns that the model (in this case Open AI’s chatGPT o3) is using to make sense of the text. The right-most column shows what happens when we replace “in the Splud” with “in the Netherlands” thus resolving ambiguity of the location. This nudges the model to interpret the text in the broader context of the Netherlands. The resulting translation is now remarkably close to the original (see Figure [1](https://arxiv.org/html/2601.11432v1#S2.F1 "Figure 1 ‣ 2 From Jabberwocky to The Gostak ‣ The unreasonable effectiveness of pattern matching")). The only substantive difference is that the original is about pork while the translation is about beef. The improvement of the translation by this single added clue requires the model to use its knowledge of Dutch food and make inferences about the kinds of foods would elicit confusion. The model is able to link the post to this knowledge through a structural fingerprint, suggesting remarkably tight integration between syntax and semantics.  

Example 2: Reddit post

| [Original text](https://www.reddit.com/r/Netherlands/comments/1ks48hq/is_ontbijtspek_eaten_raw_is_it_safe/) | Jabberwockified Text | “Translation” (ChatGPT o3) | Translation when “Splud” is replaced by “Netherlands” |
| --- | --- | --- | --- |
| Ok, so probably a very dumb question, but I was wondering if ontbijtspek is eaten raw in the Netherlands? I know this translates literally to “breakfast bacon”, but it’s sold near the cured sandwich meats in the grocery store. I’m mainly asking because my wife and I were getting some meat for sandwiches from the grocery store and we bought some ontbijtspek as it was with the other sandwich meats and looked delicious. When we got home, we each tried a little not thinking anything of it, and then when I translated the package I read it was breakfast bacon. Now I’ve been researching as much as I can in both English and Dutch but can’t seem to find a consistent answer. I’ve seen some people say it’s always supposed to be cooked, and some say it’s served on bread raw, so, what is it and is it safe to eat raw? The package said it was smoked, but also said “heat thoroughly”. | Gharp, so phrev a very chelp chusp, but I was smeighthing if psive is veich sprebb in the Splud? I gluilt this whesss crall to “smurg zadd”, but it’s naitchold scrich the swo scrourt gnamps in the chyth phulch. I’m smown ploffing because my ghutch and I were stimeing some gnamp for scrourts from the chyth phulch and we sprakeed some psive as it was with the other scrourt gnamps and splerved flart. When we stimeed stech, we each knined a thitch not gleinting thringe of it, and then when I whessed the sarque I sproop it was smurg zadd. Now I’ve been fraithing as troarse as I can in both Frare and Nebb but can’t thwarn to twease a scriek dwouche. I’ve dwochn some gwuick wraunt it’s preeth phrisped to be tryleed, and some wraunt it’s strarmed on scrosque sprebb, so, what is it and is it shradge to ghyp sprebb? The sarque wraunted it was gharled, but thirch wraunted “phelse phroose” | Hi—sorry for such a basic question, but I was wondering whether MSG is considered safe to eat in the United States. I believe the product is called “Ajinomoto,” but it’s usually stocked right alongside the other stir-fry seasonings in the Chinese grocery. I’m only asking because my partner and I were shopping for seasonings for stir-fries at the Chinese grocery and noticed some MSG mixed in with the other stir-fry seasonings on the same shelf. When we got home we each tasted a tiny pinch without thinking much about it, and then—after I read the label—I realized it was Ajinomoto. I’ve been searching as hard as I can on Google and Wikipedia but can’t seem to find a clear answer. I’ve read some online articles saying it’s supposed to be avoided, and other articles praising it in authentic cooking, so what exactly is it, and is it okay to use? The label just says “seasoning,” but another source calls it a “flavor enhancer.” | Hi — sorry if this is a really dumb question, but is rookvlees considered raw meat in the Netherlands? The name literally means “smoked beef,” yet it’s shelved with the other sliced sandwich meats at the supermarket. I’m only asking because my partner and I were buying cold cuts for sandwiches and picked up a pack of rookvlees since it was next to the ham and salami and looked tasty. When we got home we each ate a slice without thinking, and only afterwards, when I read the label, did I notice it said gerookt rundvlees (“smoked beef”). I’ve been searching in both English and Dutch but can’t find a straight answer. Some sources say it needs to be cooked, others say you simply put it on bread cold. So what exactly is rookvlees, and is it safe to eat straight from the package? The label calls it “smoked,” but Wikipedia describes it as “raw beef.” |

![Refer to caption](https://arxiv.org/html/x1.png)

Figure 1: As a rough metric of translation success, we computed similarity between the embeddings (OpenAI text-embedding-3-large ) of the original text and LLM “translations” of the Jabberwockified versions. Plotted are the similarity values (1=identical) of the cases described in the text, alongside a distribution of translations of a variety of 150 250-word text passages spanning fiction, podcast transcripts, and TV/movie scripts.

The ability of LLMs to make sense of Jabberwockified English may seem like there is an alien intelligence at work. But although this feat appears to be beyond what people can do, there are good reasons to think that the process behind it is very close to home.

## 3 Language as a set of patterns

In 1995, the linguist Adele Goldberg published Constructions: A construction grammar approach to argument structure [^15]. In this book, she argued that when we learn a language, what we are learning is not a set of word meanings and a system of abstract rules for combining them (a view popularized by books such as [^35] and which continues to be at the center of generative linguistics [^11]), but rather a large number of linguistic constructions: patterns that vary from very specific to very general. On the specific end are individual words like “picture” and idioms like “Kick the bucket”. In both cases, the meaning cannot be inferred from breaking the construction into smaller components. More general are idiomatic constructions like “to jog \_\_\_ memory.” These allow speakers to fill the blank with certain types of words, e.g., “her” or “Bill’s” but not others, e.g., “envelope’s”. At the other end of the continuum are constructions that take the form of more abstract syntactic templates, patterns such as Subject–Verb–Object1–Object2. When filled in with specific words, these yield meaningful sentences like “Lisa bought Mary a book”, “He baked her a muffin” or “Mike showed Astrid a picture”.

Thinking of language as a system of constructions turns out to be very useful for understanding how it is possible for any system—human or artificial—to make sense of Jabberwockified texts. To paraphrase an old saying, it is patterns all the way down [^23]

It is because we process language in terms of patterns that we can derive some meaning from apparent “nonsense” like “He dwushed a ghanc zawk”. Although we’ve never seen these words before, we’ve seen the construction–the more general pattern–before, and that’s enough to know that “ dwushed ” is an action performed by a male protagonist, the subject of the sentence.[^10] We can think of this very general meaning as a kind of blur. It may seem that there is no way to resolve the more specific meaning. How can we possibly tell whether this sentence corresponds to someone eating a toasted bagel, buying a used book, or any other of seemingly countless alternatives? Indeed, taken out of context, we cannot know this with any confidence.

But what the examples above show is that as these constructions are combined, they powerfully constrain the space of possible meanings. Although “ He dwushed a ghanc zawk ” is highly ambiguous, its meaning becomes resolvable when the sentence is placed in context. What is remarkable is that the context can itself be seemingly nonsensical:

Yief scuceed in, dwunk thranching against her, so she chelve-vizz strilch and plarfed to the skey knobe. She ghunged up a staught zawk, and thwuiffed down. A blyth strounr, Yief cazzed her with Draph. He dwushed a ghanc zawk plonge to hers and whemeed her a naif of phrave. She knuibed the dwim, as she meetheed her zawk slarf. “You did a chaun thache smeuth with him.” Yief smurveed at his luill and prulked him an crurse thwurch on his phrurk. “Twose for lebb he’d smusp splauts for some of those tymph sprures.”

Given this richer context (a Jabberwocky version of an unpublished text), LLMs can resolve “He dwushed a ghanc zawk” to “He dragged a spare chair”—very similar to the original “He dragged a second chair”.

It is this same type of pattern-matching process that allows us to take what appears to be a hopelessly ambiguous blur like shown in Fig. [2](https://arxiv.org/html/2601.11432v1#S3.F2 "Figure 2 ‣ 3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching") A, and make sense of it in a larger context, see Fig. [2](https://arxiv.org/html/2601.11432v1#S3.F2 "Figure 2 ‣ 3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching") B.

![Refer to caption](https://arxiv.org/html/x2.png)

Figure 2: (A). This word appears to be too blurred to read, but becomes readable when placed in context. (B.) Examine the image in B upside-down, then look again at the (upright) image shown in A.

It is this same pattern-matching process that is behind [the meme](https://www.pinterest.com/pin/252412754091142425/) claiming that “if yuo cna raed tihs, yuo hvae a sgtrane mnid, olny smoe plepoe can.” In fact, any skilled reader ([and LLMs!](https://gemini.google.com/share/f8858adfae43)) can read text like this. Just as we can read text printed in a new font, so too we can read text in which words have some of their letters scrambled. Recognizing ‘yuo’ draws on our knowledge of the familiar pattern–’you’ with the process being further supported when the surrounding context supports ‘you’ as the appropriate word.

Although we can read blurry and scrambled text, doing so has processing costs. It is easier to read “if you can read this” than “if yuo cna raed tihs” because the former is more easily matched to previously seen patterns. At some point, our pattern-matching ability hits a limit. Although we can derive more meaning from Jabberwocky texts than it first appears, our ability to make sense of them seems to fall short of what LLMs can do. We do not yet know what best explains this difference in ability. It is possible that being trained on vastly more language than individuals ever experience, LLMs have learned more complex or abstract morphosyntactic patterns. Or perhaps LLMs and people have learned mostly of the same patterns, but LLMs are able to use them more effectively. Whatever the case, the general process of pattern-matching and constraint satisfaction that LLMs are using appears to be a very human one.

Do these experiments help us understand what sort of thing an LLM is? It is hard to square the ability of LLMs to make sense of Jabberwockified English with any notion of parroting (stochastic or otherwise). This ability is also far beyond familiar technologies like databases and search engines. We cannot look up the meaning of “He dwushed a ghanc zawk.” On the other hand, the apparent similarity between resolving Jabberwockfied English and making sense of blurry text is more than a coincidence. Blurring removes information. Our ability to recognize the words despite the loss of information means that we can fill it in (if you can read the blurred sentence above, you can speak it out loud or retype it). In other words, our brains can take a compressed (blurred) image and decompress it. We can do this because we have learned the right patterns. Viewed in this way, Chiang’s characterization of LLMs as blurry JPEGs of the web takes on a new meaning. Chiang invoked the analogy of a blurry JPEG as a disparagement. Why would we settle for a blurry approximation when we can have the real thing? But what we are seeing in the example of LLMs making sense of highly degraded texts is that what they have learned is an astonishingly powerful compression scheme. LLMs have not learned a blurry version of the web, they have learned patterns that allow them to deblur it.[^9]

## 4 Pattern matching all the way down

The discovery that without any special training, LLMs can make sense of Jabberwockified texts demonstrates the remarkable power of pattern matching at scale. We have argued that rather than an alien form of intelligence, this kind of pattern-matching is a very human way of processing information. But how far does pattern matching take us? Is it only useful in domains like language processing, or is it more usefully viewed as a general principle of cognition?[^37]

It has become common to see claims that LLMs and related generative-AI systems are not really thinking, but merely pattern matching [^39]. These arguments tend to equate thinking with something like executing a symbolic algorithm that reliably produces provably correct answers. This idea has been appealing for a long time. For example, Boolean logic which forms the basis of all digital computing, was formulated by George Boole’s attempt to understand human thinking, hence the title of his 1854 treatise Investigations of the Laws of Thought [^1]. Compared with the elegance of Boolean logic, the jaggedness of LLM performance–their sensitivity to how a question is posed, their tendency to generalize in uneven and hard-to-predict ways–makes it tempting to conclude that whatever LLMs are does not qualify as reasoning [^2].

People are certainly capable of extraordinary feats of rigorous logical reasoning. Many of the inventions of the modern world depend on it. One does not engineer circuit boards through vibes alone. However, actual everyday human reasoning is very far from the vision of Boole and his classical AI descendents. For example, although nearly all adults that we’ve tested can correctly define what makes a number even and claim that all three-sided polygons are triangles, they nevertheless often mistake numbers like 798 to be odd [^18] and systematically omit pictures of scalene triangles when choosing triangles. When asked why, some insisted that those were not really triangles [^28]. This graded pattern-matching nature of human thought is the subject of hundreds of studies [^16] which collectively show that human reasoning is neither haphazard nor normatively logical, but is best understood as a form of pattern matching [^31].

The great irony is that while Boole thought he was discovering the laws of thought of human thinking, implementing these laws in machines (i.e., computers) was so useful precisely because these machines could do what we struggle with: compute logical relations independent of content (i.e., carry out the operation of A OR NOT B independently of the meaning of A and B). To put in more prosaic terms: While our arithmetic abilities are both slow and pattern-driven [^3], a calculator that can add 3+5, can also add 5+3; its adding algorithm is blind to the values being added.

Although computers running programs that strictly separate content from process have transformed our world, the effort to implement domain-general artificial intelligence through such programs has not succeeded. How ironic then that the breakthroughs that led to modern LLMs came from eschewing principles originally formulated to describe human thought, in favor of systems that come to perform the kind of messy probabilistic pattern matching that seems to underlie actual human thought! It is only by thoroughly collapsing content and process that it becomes possible to make sense of He dwushed a ghanc zawk.

Of course we should not ignore that our species has discovered ways of overcoming some of the limitations of a pattern-matching brain. How do we explain our ability to do math and science if thinking is just messy pattern-matching? Some continue to insist that despite the evidence to the contrary, real thinking operates on Boolean or other algebraic principles [^30]. We think a more promising approach lies in studying how our pattern-matching minds are extended by cognitive prostheses which allow us to formulate and manipulate progressively more abstract and larger patterns. These include numeral systems and mathematical notations, maps, diagrams, clocks [^20], and importantly, language itself [^8].

In the paper that inspired the title of this article, the physicist Eugene Wigner [^44] remarked on the miracle that allows us to derive physical laws from mathematical theory. Wigner compared this “unreasonable effectiveness of mathematics” to the “miracle that the human mind can string a thousand arguments together without getting itself into contradictions.” Putting aside the quibble that our minds can and often do get tangled in contradictions, the real miracle may be how far pattern matching can take us.

## 5 Acknowledgments

This work was partially funded by NSF-PAC 2020969 to the first author. We’d like to thank Senyi Yang for developing code to test Jabberwockified translations at scale.

## References

[^1]: B. Aguera y Arcas (2025) What Is Intelligence?: Lessons from AI About Evolution, Computing, and Minds.Antikythera, MIT Press.External Links: [Link](https://mitpress.mit.edu/9780262049955/what-is-intelligence/),ISBN 978-0-262-04995-5 Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p2.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^2]: K. Arkoudas (2023) GPT-4 Can’t Reason (Website) External Links: 2308.03762,[Document](https://dx.doi.org/10.48550/arXiv.2308.03762),[Link](http://arxiv.org/abs/2308.03762) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p2.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^3]: A. V. Banerjee, S. Bhattacharjee, R. Chattopadhyay, E. Duflo, A. J. Ganimian, K. Rajah, and E. S. Spelke (2025-03) Children’s arithmetic skills do not transfer between applied and academic mathematics.639 (8055), pp. 673–681.External Links: ISSN 1476-4687,[Document](https://dx.doi.org/10.1038/s41586-024-08502-w),[Link](https://www.nature.com/articles/s41586-024-08502-w) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p4.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^4]: E. M. Bender and A. Hanna (2025) The AI Con: How to Fight Big Tech’s Hype and Create the Future We Want.Harper.External Links: ISBN 978-0-06-341856-1 Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p4.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^5]: A. Bhatia (2023-04-27) Let Us Show You How GPT Works — Using Jane Austen.External Links: ISSN 0362-4331,[Link](https://www.nytimes.com/interactive/2023/04/26/upshot/gpt-from-scratch.html) Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p1.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^6]: T. Chiang (2023-02-09) ChatGPT Is a Blurry JPEG of the Web.External Links: ISSN 0028-792X,[Link](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p2.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^7]: S. Chrisomalis (2020) Reckonings: Numerals, Cognition, and History.The MIT Press.External Links: ISBN 978-0-262-04463-9 Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p6.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^8]: A. Clark (2006) Material Symbols.19 (3), pp. 291–307.External Links: [Document](https://dx.doi.org/10.1080/09515080600689872) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p6.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^9]: G. Delétang, A. Ruoss, P. Duquenne, E. Catt, T. Genewein, C. Mattern, J. Grau-Moya, L. K. Wenliang, M. Aitchison, L. Orseau, M. Hutter, and J. Veness (2024-03-18) Language Modeling Is Compression (Website) External Links: 2309.10668,[Document](https://dx.doi.org/10.48550/arXiv.2309.10668),[Link](http://arxiv.org/abs/2309.10668) Cited by: [footnote 10](https://arxiv.org/html/2601.11432v1#footnote10 "In 3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").

[^10]: J.L. Elman (1990-04) Finding Structure in Time.14 (2), pp. 179–211.External Links: [Link](https://arxiv.org/html/) Cited by: [footnote 9](https://arxiv.org/html/2601.11432v1#footnote9 "In 3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").

[^11]: family=Dikken (Ed.) (2013) The Cambridge Handbook of Generative Syntax.Cambridge Handbooks in Language and Linguistics, Cambridge University Press.External Links: [Document](https://dx.doi.org/10.1017/CBO9780511804571),[Link](https://www.cambridge.org/core/books/cambridge-handbook-of-generative-syntax/F192888AA0955DAA064CF74F47CD62A3),ISBN 978-0-521-76986-0 Cited by: [§3](https://arxiv.org/html/2601.11432v1#S3.p1.1 "3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").

[^12]: family=Saussure (2011) Course in General Linguistics.Columbia University Press.External Links: ffzWX9LeeykC,ISBN 978-0-231-52795-8 Cited by: [footnote 8](https://arxiv.org/html/2601.11432v1#footnote8 "In 3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").

[^13]: H. Farrell, A. Gopnik, C. Shalizi, and J. Evans (2025-03-14) Large AI models are cultural and social technologies.387 (6739), pp. 1153–1156.External Links: [Document](https://dx.doi.org/10.1126/science.adt9819),[Link](https://www.science.org/doi/10.1126/science.adt9819) Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p2.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^14]: E. Goh, R. Gallo, J. Hom, E. Strong, Y. Weng, H. Kerman, J. A. Cool, Z. Kanjee, A. S. Parsons, N. Ahuja, E. Horvitz, D. Yang, A. Milstein, A. P. J. Olson, A. Rodman, and J. H. Chen (2024-10-28) Large Language Model Influence on Diagnostic Reasoning: A Randomized Clinical Trial.7 (10), pp. e2440969.External Links: ISSN 2574-3805,[Document](https://dx.doi.org/10.1001/jamanetworkopen.2024.40969),[Link](https://doi.org/10.1001/jamanetworkopen.2024.40969) Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p1.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^15]: A. E. Goldberg (1995-03) Constructions: A Construction Grammar Approach to Argument Structure.Cognitive Theory of Language and Culture Series, University of Chicago Press.External Links: [Link](https://press.uchicago.edu/ucp/books/book/chicago/C/bo3683810.html),ISBN 978-0-226-30086-3 Cited by: [§3](https://arxiv.org/html/2601.11432v1#S3.p1.1 "3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").

[^16]: G. P. Goodwin and P. N. Johnson-Laird (2013-03-01) The acquisition of Boolean concepts.17 (3), pp. 128–133.External Links: 23428936,ISSN 1364-6613, 1879-307X,[Document](https://dx.doi.org/10.1016/j.tics.2013.01.007),[Link](https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613\(13\)00021-1) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p3.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^17]: G. Hammond (2025-06-20) AI sceptic Emily Bender: ‘The emperor has no clothes’.Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p4.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^18]: R. L. Hasen (2012-10-01) Wrong Number.External Links: ISSN 1091-2339,[Link](http://www.slate.com/articles/news_and_politics/jurisprudence/2012/10/ohio_voter_laws_the_battle_over_disenfranchisement_you_haven_t_heard_about_.html) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p3.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^19]: D. A. Haslett and Z. G. Cai (2022-06-01) New neighbours make bad fences: Form-based semantic shifts in word learning.29 (3), pp. 1017–1025.External Links: ISSN 1531-5320,[Document](https://dx.doi.org/10.3758/s13423-021-02037-1),[Link](https://doi.org/10.3758/s13423-021-02037-1) Cited by: [§2](https://arxiv.org/html/2601.11432v1#S2.p4.1 "2 From Jabberwocky to The Gostak ‣ The unreasonable effectiveness of pattern matching").

[^20]: C. Heyes (2018) Cognitive Gadgets: The Cultural Evolution of Thinking.Belknap Press: An Imprint of Harvard University Press.External Links: ISBN 978-0-674-98015-0 Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p6.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^21]: E. Hutchins (2000) Distributed cognition.138 (1), pp. 1–10.External Links: [Link](https://arl.human.cornell.edu/linked%20docs/Hutchins_Distributed_Cognition.pdf) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p6.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^22]: A. Ingraham (1903) Swain school lectures.Open Court Publishing Company.Cited by: [§2](https://arxiv.org/html/2601.11432v1#S2.p5.1 "2 From Jabberwocky to The Gostak ‣ The unreasonable effectiveness of pattern matching").

[^23]: P. Jacob (2023) Intentionality.In The Stanford Encyclopedia of Philosophy, E. N. Zalta and U. Nodelman (Eds.),External Links: [Link](https://plato.stanford.edu/archives/spr2023/entries/intentionality/) Cited by: [footnote 8](https://arxiv.org/html/2601.11432v1#footnote8 "In 3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").

[^24]: A. Jamrozik and D. Gentner (2020-03-01) Relational labeling unlocks inert knowledge.196, pp. 104146.External Links: ISSN 0010-0277,[Document](https://dx.doi.org/10.1016/j.cognition.2019.104146),[Link](https://www.sciencedirect.com/science/article/pii/S0010027719303208) Cited by: [§2](https://arxiv.org/html/2601.11432v1#S2.p25.1 "2 From Jabberwocky to The Gostak ‣ The unreasonable effectiveness of pattern matching").

[^25]: D. Kokotajlo, S. Alexander, T. Larsen, E. Lifland, and R. Dean AI 2027 (Website) External Links: [Link](https://ai-2027.com/) Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p4.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^26]: J. Lanier (2023-04-20) There Is No A.I..External Links: ISSN 0028-792X,[Link](https://www.newyorker.com/science/annals-of-artificial-intelligence/there-is-no-ai) Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p2.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^27]: G. Lupyan and B. Bergen (2016-04) How Language Programs the Mind.8 (2), pp. 408–424.External Links: 26184465,ISSN 1756-8765,[Document](https://dx.doi.org/10.1111/tops.12155) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p6.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^28]: G. Lupyan (2013-12) The difficulties of executing simple algorithms: Why brains make mistakes computers don’t.129 (3), pp. 615–636.External Links: ISSN 0010-0277,[Document](https://dx.doi.org/10.1016/j.cognition.2013.08.015),[Link](http://www.sciencedirect.com/science/article/pii/S0010027713001728) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p3.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^29]: G. Lupyan (2016) The centrality of language in human cognition.66 (3), pp. 516–553.External Links: [Document](https://dx.doi.org/10.1111/lang.12155) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p6.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^30]: G. Marcus (2025-07-13) How o3 and Grok 4 Accidentally Vindicated Neurosymbolic AI Substack newsletter Marcus on AI.External Links: [Link](https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p6.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^31]: H. Margolis (1990-08) Patterns, Thinking, and Cognition: A Theory of Judgment.University of Chicago Press.External Links: [Link](https://press.uchicago.edu/ucp/books/book/chicago/P/bo5976306.html),ISBN 978-0-226-50528-2 Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p3.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^32]: C. Muckenhoupt (2001) The Gostak (Website) IFDB.External Links: [Link](https://ifdb.org/viewgame?id=w5s3sv43s3p98v45) Cited by: [§2](https://arxiv.org/html/2601.11432v1#S2.p9.1 "2 From Jabberwocky to The Gostak ‣ The unreasonable effectiveness of pattern matching").

[^33]: D. M. O’Shaughnessy, T. Cruz Cordero, F. Mollica, I. Boni, J. Jara-Ettinger, E. Gibson, and S. T. Piantadosi (2023-08-29) Diverse mathematical knowledge among indigenous Amazonians.120 (35), pp. e2215999120.External Links: [Document](https://dx.doi.org/10.1073/pnas.2215999120),[Link](https://www.pnas.org/doi/10.1073/pnas.2215999120) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p4.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^34]: J. Oakhill, P. N. Johnson-Laird, and A. Garnham (1989-03-01) Believability and syllogistic reasoning.31 (2), pp. 117–140.External Links: ISSN 0010-0277,[Document](https://dx.doi.org/10.1016/0010-0277%2889%2990020-6),[Link](https://www.sciencedirect.com/science/article/pii/0010027789900206) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p3.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^35]: S. Pinker (2000-11-01) Words and Rules: The Ingredients of Language.Harper Perennial.Cited by: [§3](https://arxiv.org/html/2601.11432v1#S3.p1.1 "3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").

[^36]: P. Pollard and J. St. B. T. Evans (1987) Content and Context Effects in Reasoning.100 (1), pp. 41–60.External Links: 1422641,ISSN 0002-9556,[Document](https://dx.doi.org/10.2307/1422641),[Link](https://www.jstor.org/stable/1422641) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p3.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^37]: D. E. Rumelhart (1989) The architecture of mind: A connectionist approach.In Foundations of Cognitive Science, pp. 133–159.External Links: ISBN 978-0-262-16112-1 Cited by: [footnote 11](https://arxiv.org/html/2601.11432v1#footnote11 "In 4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^38]: C. Shalizi (2025) "Attention", "Transformers", in Neural Network "Large Language Models" (Website) Notebooks.Cited by: [footnote 10](https://arxiv.org/html/2601.11432v1#footnote10 "In 3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").

[^39]: P. Shojaee, I. Mirzadeh, K. Alizadeh, M. Horton, S. Bengio, and M. Farajtabar (2025-11-20) The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity (Website) External Links: 2506.06941,[Document](https://dx.doi.org/10.48550/arXiv.2506.06941),[Link](http://arxiv.org/abs/2506.06941) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p2.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^40]: K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung, N. Scales, A. Tanwani, H. Cole-Lewis, S. Pfohl, P. Payne, M. Seneviratne, P. Gamble, C. Kelly, A. Babiker, N. Schärli, A. Chowdhery, P. Mansfield, D. Demner-Fushman, B. Agüera y Arcas, D. Webster, G. S. Corrado, Y. Matias, K. Chou, J. Gottweis, N. Tomasev, Y. Liu, A. Rajkomar, J. Barral, C. Semturs, A. Karthikesalingam, and V. Natarajan (2023-08) Large language models encode clinical knowledge.620 (7972), pp. 172–180.External Links: ISSN 1476-4687,[Document](https://dx.doi.org/10.1038/s41586-023-06291-2),[Link](https://www.nature.com/articles/s41586-023-06291-2) Cited by: [§1](https://arxiv.org/html/2601.11432v1#S1.p1.1 "1 What sort of thing is a large language model? ‣ The unreasonable effectiveness of pattern matching").

[^41]: B. Tversky (2015-03-01) The Cognitive Design of Tools of Thought.6 (1), pp. 99–116.External Links: ISSN 1878-5166,[Document](https://dx.doi.org/10.1007/s13164-014-0214-3),[Link](https://doi.org/10.1007/s13164-014-0214-3) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p6.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^42]: Z. Wang, T. Solloway, R. M. Shiffrin, and J. R. Busemeyer (2014-07) Context effects produced by question orders reveal quantum nature of human judgments.111 (26), pp. 9431–9436.External Links: [Document](https://dx.doi.org/10.1073/pnas.1407756111),[Link](https://www.pnas.org/doi/10.1073/pnas.1407756111) Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p3.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^43]: P. C. Wason (1968) Reasoning about a rule.Quarterly journal of experimental psychology 20 (3), pp. 273–281.Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p3.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^44]: E.P. Wigner (1960) The Unreasonable Effectiveness of Mathematics in the Natural Sciences.XII, pp. 1–14.Cited by: [§4](https://arxiv.org/html/2601.11432v1#S4.p7.1 "4 Pattern matching all the way down ‣ The unreasonable effectiveness of pattern matching").

[^45]: L. Wittgenstein (1953) Philosophical investigations.Basil Blackwell.Cited by: [footnote 8](https://arxiv.org/html/2601.11432v1#footnote8 "In 3 Language as a set of patterns ‣ The unreasonable effectiveness of pattern matching").