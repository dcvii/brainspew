---
title: "Executive Briefing: Your Cloud Provider Is Your Competitor for AI Compute"
source: "https://natesnewsletter.substack.com/p/executive-briefing-the-global-inference?publication_id=1373231&post_id=187037906&isFreemail=true&r=7br8e&triedRedirect=true"
author:
  - "[[By Nate]]"
published:
created: 2026-02-08
description:
tags:
  - "clippings"
---
---

---

Your CFO approved the AI budget six months ago. The pilots worked. The rollouts are underway. And now someone in procurement is telling you that the inference capacity you need for Q3 doesn’t exist — not at your current vendor, not at the backup, not at any price you’d previously considered reasonable.

The enterprises getting hit hardest aren’t the ones who skipped AI planning — they’re the ones who planned well and are discovering that the infrastructure they need doesn’t exist in sufficient quantities.

Over the past three years, a growing share of enterprise software, customer-facing services, and knowledge work has become dependent on AI capabilities — capabilities that run on inference compute. That compute is now physically constrained. DRAM contract prices are rising 90-95% in a single quarter. The GPUs your workloads need are sold out to hyperscalers through multi-year commitments. And the new fabrication capacity that’s supposed to fix this won’t arrive at meaningful scale until late 2027 at the earliest.

The demand side isn’t waiting. At AI-forward enterprises, consumption is approaching 10x annual growth. Agentic systems — AI calling AI in automated loops — are compounding that curve in ways most capacity plans haven’t accounted for. Google disclosed that it now processes 1.3 quadrillion tokens per month, up 33% from just months earlier. That’s your leading indicator for where enterprise consumption is heading.

The hyperscalers who sell you compute are also your competitors for it. Google needs GPUs for Gemini. Microsoft needs them for Copilot. Amazon needs them for its own AI products. When supply is scarce, they will prioritize themselves. They already are.

This briefing is about what that means for your enterprise and what to do about it in the next 6-12 months.

**This briefing covers:**

- **The demand shock.** Why enterprise AI consumption is growing by orders of magnitude — and why agentic systems break every existing capacity model.
- **The supply wall.** Memory, fabrication, and GPU constraints that won’t resolve before late 2027, and why new domestic capacity doesn’t help you now.
- **The pricing reckoning.** Why inference costs will spike 2-3x (not rise gradually), and what that does to margins across every business model.
- **The geopolitical dimension.** Concentration risk in Taiwan, South Korea, and the Netherlands — and why reshoring is a decade-long fix for a near-term crisis.
- **Why traditional planning fails.** Capex traps, depreciation illusions, and committed-use agreements that become anchors when demand is unpredictable.
- **The strategic playbook.** Six principles for securing capacity, building routing intelligence, and maintaining optionality through the crisis.
- **Scenarios and equilibrium.** What the next 36 months look like under base, severe, and optimistic cases — and what the world looks like when supply catches up.

Let me walk you through the numbers, the constraints, and what I think the playbook looks like from here.