---
title: "Nobel Prizes and The AI Hype Hall of Fame"
source: "https://garymarcus.substack.com/p/nobel-prizes-and-the-ai-hype-hall?publication_id=888615&post_id=158720260&isFreemail=true&r=7br8e&triedRedirect=true"
author:
  - "[[Gary Marcus]]"
published: 2024-10-11
created: 2025-03-09
description: "GPT-5 may not be here, but just wait til you see the new round of hype"
tags:
  - "clippings"
---
### GPT-5 may not be here, but just wait til you see the new round of hype

![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99e69254-b628-4aaf-92f1-adcd20026121_1320x1270.png)

*The AI Hype Hall of Fame, as envisioned by Grok*

“*We should stop training scientists now. It’s just completely obvious that within three years, AI is going to do better than Nobel Laureates*.”

is the new

“*We should stop training radiologists now. It’s just completely obvious that within five years, deep learning is going to do better than radiologists.*”

§

[The latter quote is of course from Geoff Hinton, 2016](https://www.statnews.com/2019/10/23/advancing-ai-health-care-trust/), and it deserves to be the centerpiece in an AI Hype Hall of Fame, along with Elon Musk’s 2019 prediction

> “I feel very confident predicting that there will be autonomous robotaxis from Tesla next year — not in all jurisdictions because we won’t have regulatory approval everywhere … From our standpoint, if you fast forward a year, maybe a year and three months, but next year for sure, we’ll have over a million robotaxis on the road.”

Nine years post Hinton, we still haven’t replace a single radiologist, as far as I know. Musk’s robotaxi promise hasn’t fared much better.

§

The “stop training scientists” line at the opening of this essay, said with touch of humor, isn’t a literal quote, it is a composite. It was inspired by Anthropic’s CEO Dario Amodei, who in October 2024 promised us AI [“smarter than a Nobel Prize winner across most relevant fields – biology, programming, math, engineering, writing” as early as 2026](https://darioamodei.com/machines-of-loving-grace). It was also inspired by his co-founder Jack Clark, who more less just promised POLITICO essentially the same, “[We have this notion that in late 2026, or early 2027, powerful AI systems will be built that will have intellectual capabilities that match or exceed Nobel Prize winners](https://www.politico.com/newsletters/digital-future-daily/2025/03/07/5-questions-for-jack-clark-00218274).” And it was inspired by the physicist Max Tegmark, who a few days ago endorsed the above position with such certainty that he chided his MIT colleagues for not the (alleged)“[coming tsunami](https://x.com/tegmark/status/1898023694892404902?s=61)”.

I think this is absurd beyond words. So absurd, and so beyond words that I made up a graph instead:

![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6930ceed-15b0-47e5-8954-b102d33b36a5_1283x709.png)

As one person on X put it, in reply to Tegmark,

> Al can also "almost" drive a car. It can also "almost" draw a picture of a full glass of wine. So yeah, it can also "almost" make novel scientific discoveries.

Per the 80:20 rule I described a few days ago, it’s easy to make demos; 80% of driving, 80% of some scientific problem, etc. Getting the last 20% is often really really hard.

I don’t doubt that AI built in 2026 or 2027 will be valuable to future Nobel Laureates. Human scientists will get plenty of leverage from AI (just as they did with databases, calculators etc). But I highly doubt that in the next few years AI’s will conceive of and execute Nobel-caliber work on their own. Even in the best work, like Google’s [new AI co-scientist](https://blog.google/feed/google-research-ai-co-scientist/), humans scientists are still choosing the research goals.

![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3571528f-57ae-4a64-8016-b5b4b95af35a_1159x580.png)

That is not going to magically change next year, at a time when AI still can’t reliably solving river-crossing problems. (Heck, if you look closely at the picture at the top, Grok doesn’t even seem to know that Elon Musk doesn’t have a twin.)

The reality is that (a) Nobel-calibre science is a *lot* harder than driving, which we still have not reliably solved, and (b) Nobel-calibre science requires sound logic, reliable causal reasoning, and originality, and none of those are firmly in the grasp of current AI. Worse, I think the DOGE world will lean on these absurd predictions to justify the outrageous cuts of scientific institutions.

Science needs every bit of help it can get right now. Playing make-believe with predictions isn’t helping.

***Gary Marcus** wishes that just once a prominent person spouting these AGI-is-imminent predictions would agree to public, moderated debate.*

29 Likes∙

[3 Restacks](https://substack.com/note/p-158720260/restacks?utm_source=substack&utm_content=facepile-restacks)